{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân Tích Toàn Diện FaceNet Model\n",
    "\n",
    "Notebook này thực hiện phân tích và trực quan hóa toàn bộ kết quả training và đánh giá của mô hình FaceNet.\n",
    "\n",
    "## Nội dung:\n",
    "1. **Training Analysis**: Loss curves, Accuracy curves, Learning trajectory\n",
    "2. **Evaluation Metrics**: Top-1/Top-5 Accuracy, AUC, EER\n",
    "3. **ROC Curve Analysis**: Đường cong ROC chi tiết\n",
    "4. **Threshold Analysis**: Phân tích ngưỡng quyết định\n",
    "5. **Confusion Matrix**: Ma trận nhầm lẫn\n",
    "6. **Model Configuration**: Cấu hình huấn luyện\n",
    "7. **Báo cáo tổng hợp**: Đánh giá toàn diện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup và Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "LOGS_DIR = Path('../logs/facenet')\n",
    "print(f\"Logs directory: {LOGS_DIR.absolute()}\")\n",
    "print(f\"Các file có sẵn:\")\n",
    "for f in sorted(LOGS_DIR.glob('*')):\n",
    "    print(f\"  - {f.name} ({f.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dữ Liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOGS_DIR / 'training_history.json', 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "with open(LOGS_DIR / 'facenet_evaluation_report.json', 'r') as f:\n",
    "    eval_report = json.load(f)\n",
    "\n",
    "with open(LOGS_DIR / 'facenet_evaluation_data.json', 'r') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "predictions_df = pd.read_csv(LOGS_DIR / 'facenet_predictions.csv')\n",
    "\n",
    "metrics = eval_report['metrics']\n",
    "metadata = eval_data['metadata']\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Training epochs: {len(training_data['train_loss'])}\")\n",
    "print(f\"Number of identities: {metadata['num_identities']}\")\n",
    "print(f\"Number of samples: {metadata['num_samples']}\")\n",
    "print(f\"Embedding size: {metadata['embedding_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 1: PHÂN TÍCH QUÁ TRÌNH TRAINING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Curves - Loss và Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "epochs = list(range(1, len(training_data['train_loss']) + 1))\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(epochs, training_data['train_loss'], 'b-', lw=2, label='Train Loss', alpha=0.8)\n",
    "ax1.plot(epochs, training_data['val_loss'], 'r-', lw=2, label='Val Loss', alpha=0.8)\n",
    "ax1.fill_between(epochs, training_data['train_loss'], training_data['val_loss'], alpha=0.2, color='gray')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Triplet Loss Over Training', fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "train_acc = [x * 100 for x in training_data['train_acc']]\n",
    "val_acc = [x * 100 for x in training_data['val_acc']]\n",
    "ax2.plot(epochs, train_acc, 'b-', lw=2, label='Train Acc', alpha=0.8)\n",
    "ax2.plot(epochs, val_acc, 'r-', lw=2, label='Val Acc', alpha=0.8)\n",
    "ax2.fill_between(epochs, train_acc, val_acc, alpha=0.2, color='gray')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy Over Training', fontweight='bold')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "gap = np.array(train_acc) - np.array(val_acc)\n",
    "colors = ['green' if g < 5 else 'orange' if g < 10 else 'red' for g in gap]\n",
    "ax3.bar(epochs, gap, color=colors, alpha=0.7)\n",
    "ax3.axhline(y=5, color='orange', linestyle='--', label='Warning threshold (5%)')\n",
    "ax3.axhline(y=10, color='red', linestyle='--', label='Overfitting threshold (10%)')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Gap (%)')\n",
    "ax3.set_title('Generalization Gap (Train - Val)', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(epochs, training_data['lr'], 'g-', lw=2, marker='o', markersize=3)\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Learning Rate')\n",
    "ax4.set_title('Learning Rate Schedule', fontweight='bold')\n",
    "ax4.set_yscale('log')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'training_curves_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Final Train Loss: {training_data['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final Val Loss: {training_data['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Final Train Acc: {train_acc[-1]:.2f}%\")\n",
    "print(f\"  Final Val Acc: {val_acc[-1]:.2f}%\")\n",
    "print(f\"  Final Gap: {gap[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Dynamics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "train_loss_diff = np.diff(training_data['train_loss'])\n",
    "val_loss_diff = np.diff(training_data['val_loss'])\n",
    "ax1.plot(epochs[1:], train_loss_diff, 'b-', lw=1.5, label='Train', alpha=0.7)\n",
    "ax1.plot(epochs[1:], val_loss_diff, 'r-', lw=1.5, label='Val', alpha=0.7)\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss Change')\n",
    "ax1.set_title('Loss Change per Epoch', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "window = 5\n",
    "train_loss_smooth = np.convolve(training_data['train_loss'], np.ones(window)/window, mode='valid')\n",
    "val_loss_smooth = np.convolve(training_data['val_loss'], np.ones(window)/window, mode='valid')\n",
    "ax2.plot(range(1, len(train_loss_smooth)+1), train_loss_smooth, 'b-', lw=2, label='Train (smoothed)')\n",
    "ax2.plot(range(1, len(val_loss_smooth)+1), val_loss_smooth, 'r-', lw=2, label='Val (smoothed)')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title(f'Smoothed Loss (window={window})', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = axes[2]\n",
    "loss_ratio = np.array(training_data['val_loss']) / np.array(training_data['train_loss'])\n",
    "colors = ['green' if r < 1.2 else 'orange' if r < 1.5 else 'red' for r in loss_ratio]\n",
    "ax3.scatter(epochs, loss_ratio, c=colors, s=50, alpha=0.7)\n",
    "ax3.axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(y=1.2, color='orange', linestyle='--', label='Warning (1.2)')\n",
    "ax3.axhline(y=1.5, color='red', linestyle='--', label='Overfitting (1.5)')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Val/Train Loss Ratio')\n",
    "ax3.set_title('Loss Ratio Analysis', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'loss_dynamics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 2: ĐÁNH GIÁ MÔ HÌNH\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('                    FACENET EVALUATION SUMMARY')\n",
    "print('='*70)\n",
    "print(f'\\n  Model: {metadata[\"model\"]}')\n",
    "print(f'  Embedding Size: {metadata[\"embedding_size\"]}')\n",
    "print(f'  Number of Identities: {metadata[\"num_identities\"]}')\n",
    "print(f'  Number of Test Samples: {metadata[\"num_samples\"]}')\n",
    "print(f'  Evaluation Timestamp: {metadata[\"timestamp\"]}')\n",
    "print('\\n' + '-'*70)\n",
    "print('  RECOGNITION METRICS:')\n",
    "print('-'*70)\n",
    "print(f'  Top-1 Accuracy: {metrics[\"top1_accuracy\"]:.2f}%')\n",
    "print(f'  Top-5 Accuracy: {metrics[\"top5_accuracy\"]:.2f}%')\n",
    "print('\\n' + '-'*70)\n",
    "print('  VERIFICATION METRICS:')\n",
    "print('-'*70)\n",
    "print(f'  AUC-ROC: {metrics[\"auc\"]:.4f}')\n",
    "print(f'  EER (Equal Error Rate): {metrics[\"eer\"]*100:.2f}%')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "metric_names = ['Top-1 Acc', 'Top-5 Acc', 'AUC×100']\n",
    "metric_values = [metrics['top1_accuracy'], metrics['top5_accuracy'], metrics['auc'] * 100]\n",
    "colors = ['#3498db', '#2ecc71', '#9b59b6']\n",
    "bars = ax1.bar(metric_names, metric_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_ylim([0, 105])\n",
    "ax1.set_ylabel('Value (%)')\n",
    "ax1.set_title('Recognition & Verification Metrics', fontweight='bold')\n",
    "for bar, val in zip(bars, metric_values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{val:.1f}%', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "sizes = [100 - metrics['eer']*100, metrics['eer']*100]\n",
    "labels = ['Correct', 'EER']\n",
    "colors_pie = ['#2ecc71', '#e74c3c']\n",
    "explode = (0.02, 0.05)\n",
    "ax2.pie(sizes, explode=explode, labels=labels, colors=colors_pie, autopct='%1.2f%%',\n",
    "        shadow=True, startangle=90, textprops={'fontsize': 11})\n",
    "ax2.set_title('Equal Error Rate Analysis', fontweight='bold')\n",
    "\n",
    "ax3 = axes[2]\n",
    "categories = ['Top-1', 'Top-5', 'AUC', '1-EER']\n",
    "values = [\n",
    "    metrics['top1_accuracy'] / 100,\n",
    "    metrics['top5_accuracy'] / 100,\n",
    "    metrics['auc'],\n",
    "    1 - metrics['eer']\n",
    "]\n",
    "angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
    "values_radar = values + [values[0]]\n",
    "angles += angles[:1]\n",
    "ax3 = plt.subplot(133, polar=True)\n",
    "ax3.plot(angles, values_radar, 'o-', linewidth=2, color='#3498db')\n",
    "ax3.fill(angles, values_radar, alpha=0.25, color='#3498db')\n",
    "ax3.set_xticks(angles[:-1])\n",
    "ax3.set_xticklabels(categories)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.set_title('Overall Performance Radar', fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'metrics_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_img_path = LOGS_DIR / 'facenet_roc_curve.png'\n",
    "if roc_img_path.exists():\n",
    "    print(\"ROC Curve:\")\n",
    "    display(Image(filename=str(roc_img_path), width=700))\n",
    "    print(f\"\\nAUC Score: {metrics['auc']:.4f}\")\n",
    "    print(f\"Interpretation: \", end='')\n",
    "    if metrics['auc'] >= 0.95:\n",
    "        print(\"Excellent - Model có khả năng phân biệt rất tốt\")\n",
    "    elif metrics['auc'] >= 0.90:\n",
    "        print(\"Good - Model có khả năng phân biệt tốt\")\n",
    "    elif metrics['auc'] >= 0.80:\n",
    "        print(\"Fair - Model có khả năng phân biệt khá\")\n",
    "    else:\n",
    "        print(\"Poor - Cần cải thiện model\")\n",
    "else:\n",
    "    print(\"ROC curve image not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_img_path = LOGS_DIR / 'facenet_threshold_analysis.png'\n",
    "if threshold_img_path.exists():\n",
    "    print(\"Threshold Analysis:\")\n",
    "    display(Image(filename=str(threshold_img_path), width=700))\n",
    "    print(f\"\\nOptimal Threshold Analysis:\")\n",
    "    print(f\"  EER (Equal Error Rate): {metrics['eer']*100:.2f}%\")\n",
    "    print(f\"  EER là điểm mà FAR = FRR\")\n",
    "else:\n",
    "    print(\"Threshold analysis image not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_img_path = LOGS_DIR / 'facenet_confusion_matrix.png'\n",
    "if cm_img_path.exists():\n",
    "    print(\"Confusion Matrix:\")\n",
    "    display(Image(filename=str(cm_img_path), width=700))\n",
    "else:\n",
    "    print(\"Confusion matrix image not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predictions DataFrame Shape: {predictions_df.shape}\")\n",
    "print(f\"\\nColumns: {list(predictions_df.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "display(predictions_df.head(10))\n",
    "\n",
    "if 'correct' in predictions_df.columns:\n",
    "    correct_count = predictions_df['correct'].sum()\n",
    "    total_count = len(predictions_df)\n",
    "    print(f\"\\nCorrect Predictions: {correct_count}/{total_count} ({correct_count/total_count*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'similarity' in predictions_df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(predictions_df['similarity'], bins=50, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "    ax1.set_xlabel('Similarity Score')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Similarity Scores', fontweight='bold')\n",
    "    ax1.axvline(x=predictions_df['similarity'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {predictions_df[\"similarity\"].mean():.3f}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    if 'correct' in predictions_df.columns:\n",
    "        ax2 = axes[1]\n",
    "        correct_sims = predictions_df[predictions_df['correct'] == True]['similarity']\n",
    "        incorrect_sims = predictions_df[predictions_df['correct'] == False]['similarity']\n",
    "        ax2.hist(correct_sims, bins=30, color='green', alpha=0.6, label=f'Correct (n={len(correct_sims)})')\n",
    "        ax2.hist(incorrect_sims, bins=30, color='red', alpha=0.6, label=f'Incorrect (n={len(incorrect_sims)})')\n",
    "        ax2.set_xlabel('Similarity Score')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Similarity by Prediction Correctness', fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(LOGS_DIR / 'similarity_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 3: CẤU HÌNH VÀ BÁO CÁO\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('                    MODEL CONFIGURATION')\n",
    "print('='*70)\n",
    "print(f'\\n  Model Architecture: FaceNet (Inception-ResNet v1)')\n",
    "print(f'  Embedding Size: {metadata[\"embedding_size\"]}')\n",
    "print(f'  Loss Function: Triplet Loss with Semi-Hard Negative Mining')\n",
    "print(f'\\n  Training Configuration:')\n",
    "print(f'    - Epochs: {len(training_data[\"train_loss\"])}')\n",
    "print(f'    - Initial Learning Rate: {training_data[\"lr\"][0]:.6f}')\n",
    "print(f'    - Final Learning Rate: {training_data[\"lr\"][-1]:.6f}')\n",
    "print(f'\\n  Dataset:')\n",
    "print(f'    - Number of Identities: {metadata[\"num_identities\"]}')\n",
    "print(f'    - Number of Test Samples: {metadata[\"num_samples\"]}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comprehensive Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'model': 'FaceNet',\n",
    "    'embedding_size': metadata['embedding_size'],\n",
    "    'epochs': len(training_data['train_loss']),\n",
    "    'num_identities': metadata['num_identities'],\n",
    "    'num_samples': metadata['num_samples'],\n",
    "    'final_train_loss': training_data['train_loss'][-1],\n",
    "    'final_val_loss': training_data['val_loss'][-1],\n",
    "    'final_train_acc': training_data['train_acc'][-1] * 100,\n",
    "    'final_val_acc': training_data['val_acc'][-1] * 100,\n",
    "    'top1_accuracy': metrics['top1_accuracy'],\n",
    "    'top5_accuracy': metrics['top5_accuracy'],\n",
    "    'auc': metrics['auc'],\n",
    "    'eer': metrics['eer'],\n",
    "    'generalization_gap': (training_data['train_acc'][-1] - training_data['val_acc'][-1]) * 100\n",
    "}\n",
    "\n",
    "with open(LOGS_DIR / 'comprehensive_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('='*70)\n",
    "print('                 COMPREHENSIVE SUMMARY REPORT')\n",
    "print('='*70)\n",
    "print(json.dumps(summary, indent=2))\n",
    "print('='*70)\n",
    "print(f'\\nSummary saved to: {LOGS_DIR / \"comprehensive_summary.json\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('                    PERFORMANCE ASSESSMENT')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n1. RECOGNITION PERFORMANCE:')\n",
    "if metrics['top1_accuracy'] >= 90:\n",
    "    print(f'   [EXCELLENT] Top-1 Accuracy: {metrics[\"top1_accuracy\"]:.2f}%')\n",
    "elif metrics['top1_accuracy'] >= 80:\n",
    "    print(f'   [GOOD] Top-1 Accuracy: {metrics[\"top1_accuracy\"]:.2f}%')\n",
    "else:\n",
    "    print(f'   [NEEDS IMPROVEMENT] Top-1 Accuracy: {metrics[\"top1_accuracy\"]:.2f}%')\n",
    "\n",
    "print('\\n2. VERIFICATION PERFORMANCE:')\n",
    "if metrics['auc'] >= 0.95:\n",
    "    print(f'   [EXCELLENT] AUC: {metrics[\"auc\"]:.4f}')\n",
    "elif metrics['auc'] >= 0.90:\n",
    "    print(f'   [GOOD] AUC: {metrics[\"auc\"]:.4f}')\n",
    "else:\n",
    "    print(f'   [NEEDS IMPROVEMENT] AUC: {metrics[\"auc\"]:.4f}')\n",
    "\n",
    "print('\\n3. GENERALIZATION:')\n",
    "gap = summary['generalization_gap']\n",
    "if gap < 5:\n",
    "    print(f'   [EXCELLENT] Generalization Gap: {gap:.2f}% - Model generalizes well')\n",
    "elif gap < 10:\n",
    "    print(f'   [GOOD] Generalization Gap: {gap:.2f}% - Slight overfitting')\n",
    "else:\n",
    "    print(f'   [WARNING] Generalization Gap: {gap:.2f}% - Significant overfitting')\n",
    "\n",
    "print('\\n4. OVERALL ASSESSMENT:')\n",
    "overall_score = (metrics['top1_accuracy']/100 + metrics['auc'] + (1 - metrics['eer'])) / 3 * 100\n",
    "print(f'   Overall Score: {overall_score:.2f}/100')\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}