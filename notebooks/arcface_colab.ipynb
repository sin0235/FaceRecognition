{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "torch cuda: False 12.6\n",
            "torch cuda: False 12.6\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "import torch\n",
        "print(\"torch cuda:\", torch.cuda.is_available(), torch.version.cuda)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mount failed\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for checkpoints/logs\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROOT= /content/FaceRecognition\n",
            "DRIVE_ROOT= /content/drive/MyDrive/FaceRecognition\n"
          ]
        }
      ],
      "source": [
        "# Set paths\n",
        "import os\n",
        "ROOT = \"/content/FaceRecognition\"\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/FaceRecognition\"\n",
        "os.makedirs(ROOT, exist_ok=True)\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "print(\"ROOT=\", ROOT)\n",
        "print(\"DRIVE_ROOT=\", DRIVE_ROOT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/FaceRecognition'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "/content/FaceRecognition\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "/content/FaceRecognition\n"
          ]
        }
      ],
      "source": [
        "# Clone repository từ GitHub\n",
        "REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\"  \n",
        "if not os.path.exists(os.path.join(ROOT, \".git\")):\n",
        "    !git clone $REPO_URL $ROOT\n",
        "else:\n",
        "    %cd $ROOT\n",
        "    !git pull\n",
        "%cd $ROOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chưa có dữ liệu trong Drive, bỏ qua sync\n"
          ]
        }
      ],
      "source": [
        "# Sync dữ liệu từ Drive (nếu có)\n",
        "# Bỏ qua bước này nếu dữ liệu đã có trong repo hoặc sẽ tải riêng\n",
        "import shutil\n",
        "if os.path.exists(os.path.join(DRIVE_ROOT, \"data\")):\n",
        "    print(\"Đang sync dữ liệu từ Drive...\")\n",
        "    shutil.copytree(os.path.join(DRIVE_ROOT, \"data\"), \n",
        "                    os.path.join(ROOT, \"data\"), \n",
        "                    dirs_exist_ok=True)\n",
        "    print(\"Sync hoàn tất\")\n",
        "else:\n",
        "    print(\"Chưa có dữ liệu trong Drive, bỏ qua sync\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.0 (from versions: 2.2.0+cu118, 2.2.1+cu118, 2.2.2+cu118, 2.3.0+cu118, 2.3.1+cu118, 2.4.0+cu118, 2.4.1+cu118, 2.5.0+cu118, 2.5.1+cu118, 2.6.0+cu118, 2.7.0+cu118, 2.7.1+cu118)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement mxnet-cu118==1.9.1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mxnet-cu118==1.9.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement mxnet-cu118==1.9.1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mxnet-cu118==1.9.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies (CUDA 11.8 defaults on Colab)\n",
        "%pip install -q torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install -q mxnet-cu118==1.9.1 onnxruntime-gpu==1.16.0 insightface==0.7.3\n",
        "%pip install -q -r requirements.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mxnet'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-400379787.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Quick GPU sanity checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mxnet gpus:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Quick GPU sanity checks\n",
        "import mxnet as mx\n",
        "import onnxruntime as ort\n",
        "import torch\n",
        "print(\"mxnet gpus:\", mx.context.num_gpus())\n",
        "print(\"onnxruntime device:\", ort.get_device())\n",
        "print(\"torch cuda:\", torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data/checkpoints paths\n",
        "CHECKPOINT_DIR = os.path.join(DRIVE_ROOT, \"models\", \"checkpoints\")\n",
        "DATA_DIR = os.path.join(DRIVE_ROOT, \"data\")\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "print(\"CHECKPOINT_DIR=\", CHECKPOINT_DIR)\n",
        "print(\"DATA_DIR=\", DATA_DIR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cấu hình đường dẫn\n",
        "CONFIG_PATH = os.path.join(ROOT, \"configs\", \"arcface_config.yaml\")\n",
        "PRETRAINED_BACKBONE = os.path.join(CHECKPOINT_DIR, \"ms1mv2_resnet50.pth\")\n",
        "\n",
        "# Kiểm tra file config\n",
        "if os.path.exists(CONFIG_PATH):\n",
        "    print(f\"Config file tồn tại: {CONFIG_PATH}\")\n",
        "else:\n",
        "    print(f\"Không tìm thấy config: {CONFIG_PATH}\")\n",
        "\n",
        "# Thông tin về pretrained weights\n",
        "if os.path.exists(PRETRAINED_BACKBONE):\n",
        "    print(f\"Pretrained weights tồn tại: {PRETRAINED_BACKBONE}\")\n",
        "else:\n",
        "    print(f\"Chưa có pretrained weights: {PRETRAINED_BACKBONE}\")\n",
        "    print(\"Mô hình sẽ sử dụng ImageNet pretrained từ torchvision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kiểm tra và chạy training\n",
        "TRAIN_SCRIPT = os.path.join(ROOT, \"models\", \"arcface\", \"train_arcface.py\")\n",
        "\n",
        "if not os.path.exists(TRAIN_SCRIPT):\n",
        "    print(f\"Thiếu training script: {TRAIN_SCRIPT}\")\n",
        "else:\n",
        "    print(f\"Training script tồn tại: {TRAIN_SCRIPT}\")\n",
        "    \n",
        "    # Kiểm tra dữ liệu\n",
        "    train_csv = os.path.join(ROOT, \"data\", \"processed\", \"train_metadata.csv\")\n",
        "    val_csv = os.path.join(ROOT, \"data\", \"processed\", \"val_metadata.csv\")\n",
        "    \n",
        "    if not os.path.exists(train_csv):\n",
        "        print(f\"Chưa có dữ liệu training: {train_csv}\")\n",
        "        print(\"Vui lòng chuẩn bị dữ liệu trước khi training!\")\n",
        "    elif not os.path.exists(val_csv):\n",
        "        print(f\"Chưa có dữ liệu validation: {val_csv}\")\n",
        "        print(\"Vui lòng chuẩn bị dữ liệu trước khi training!\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"BẮT ĐẦU TRAINING\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        # Chạy training với đầy đủ arguments\n",
        "        !python $TRAIN_SCRIPT \\\n",
        "            --config $CONFIG_PATH \\\n",
        "            --pretrained_backbone $PRETRAINED_BACKBONE \\\n",
        "            --checkpoint_dir $CHECKPOINT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test model sau khi training\n",
        "import sys\n",
        "sys.path.append(ROOT)\n",
        "\n",
        "from models.arcface.arcface_model import ArcFaceModel, test_model\n",
        "\n",
        "print(\"Testing ArcFace Model...\")\n",
        "test_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best checkpoint và extract embeddings\n",
        "import torch\n",
        "from models.arcface.arcface_model import ArcFaceModel\n",
        "\n",
        "checkpoint_path = os.path.join(CHECKPOINT_DIR, \"arcface_best.pth\")\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Loading checkpoint: {checkpoint_path}\")\n",
        "    \n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    num_classes = len(checkpoint['config']['data'].get('num_classes', 100))\n",
        "    \n",
        "    model = ArcFaceModel(num_classes=num_classes, embedding_size=512)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Loaded best model - Epoch {checkpoint['epoch']}\")\n",
        "    print(f\"Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
        "    \n",
        "    # Test inference\n",
        "    dummy_input = torch.randn(1, 3, 112, 112)\n",
        "    with torch.no_grad():\n",
        "        embedding = model.extract_features(dummy_input)\n",
        "    \n",
        "    print(f\"Embedding shape: {embedding.shape}\")\n",
        "    print(\"Model sẵn sàng cho inference!\")\n",
        "else:\n",
        "    print(f\"Không tìm thấy checkpoint: {checkpoint_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
