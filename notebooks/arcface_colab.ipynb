{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "torch cuda: False 12.6\n",
            "torch cuda: False 12.6\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "import torch\n",
        "print(\"torch cuda:\", torch.cuda.is_available(), torch.version.cuda)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è ƒêang ch·∫°y local (kh√¥ng ph·∫£i Colab)\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (ch·ªâ ch·∫°y tr√™n Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IS_COLAB = True\n",
        "    print(\"ƒêang ch·∫°y tr√™n Google Colab\")\n",
        "except:\n",
        "    IS_COLAB = False\n",
        "    print(\"ƒêang ch·∫°y local (kh√¥ng ph·∫£i Colab)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Platform: linux\n",
            "ROOT= /content\n",
            "DRIVE_ROOT= None\n",
            "ROOT exists: True\n",
            "Configs exists: False\n"
          ]
        }
      ],
      "source": [
        "# Set paths (t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh cho local ho·∫∑c Colab)\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if IS_COLAB:\n",
        "    ROOT = \"/content/FaceRecognition\"\n",
        "    DRIVE_ROOT = \"/content/drive/MyDrive/FaceRecognition\"\n",
        "else:\n",
        "    # Local - check if running on Windows path (D:\\ drive)\n",
        "    # Hardcode v√¨ kernel c√≥ th·ªÉ ch·∫°y tr√™n WSL\n",
        "    ROOT = r\"D:\\HCMUTE_project\\DIP\\FaceRecognition\"\n",
        "    # N·∫øu D:\\ kh√¥ng t·ªìn t·∫°i, fallback to current directory\n",
        "    if not os.path.exists(ROOT):\n",
        "        ROOT = os.path.dirname(os.path.abspath(os.getcwd()))\n",
        "        if not os.path.exists(os.path.join(ROOT, 'configs')):\n",
        "            ROOT = os.getcwd()\n",
        "    DRIVE_ROOT = None\n",
        "    \n",
        "if DRIVE_ROOT:\n",
        "    os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "    \n",
        "print(\"Platform:\", sys.platform)\n",
        "print(\"ROOT=\", ROOT)\n",
        "print(\"DRIVE_ROOT=\", DRIVE_ROOT)\n",
        "print(f\"ROOT exists: {os.path.exists(ROOT)}\")\n",
        "print(f\"Configs exists: {os.path.exists(os.path.join(ROOT, 'configs'))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒêang ch·∫°y local, b·ªè qua clone repo\n",
            "Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Clone/Update repository (ch·ªâ tr√™n Colab)\n",
        "if IS_COLAB:\n",
        "    import subprocess\n",
        "    import shutil\n",
        "    from getpass import getpass\n",
        "    \n",
        "    REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\"\n",
        "    \n",
        "    # Ki·ªÉm tra xem ƒë√£ c√≥ git credentials ch∆∞a\n",
        "    if not os.path.exists(ROOT) or not os.path.exists(os.path.join(ROOT, \".git\")):\n",
        "        print(\"=== ƒêƒÇNG NH·∫¨P GITHUB ===\")\n",
        "        print(\"ƒê·ªÉ clone private repo, c·∫ßn GitHub Personal Access Token\")\n",
        "        print(\"T·∫°o token t·∫°i: https://github.com/settings/tokens\")\n",
        "        print(\"Quy·ªÅn c·∫ßn: repo (Full control of private repositories)\\n\")\n",
        "        \n",
        "        github_token = getpass(\"Nh·∫≠p GitHub Token (hidden): \")\n",
        "        \n",
        "        if github_token.strip():\n",
        "            # Configure git credentials\n",
        "            !git config --global credential.helper store\n",
        "            \n",
        "            # Th√™m token v√†o URL\n",
        "            username = \"sin0235\"\n",
        "            auth_url = f\"https://{username}:{github_token}@github.com/sin0235/FaceRecognition.git\"\n",
        "            \n",
        "            if os.path.exists(ROOT):\n",
        "                print(\"X√≥a th∆∞ m·ª•c c≈©...\")\n",
        "                shutil.rmtree(ROOT)\n",
        "            \n",
        "            print(f\"ƒêang clone repository...\")\n",
        "            result = subprocess.run(['git', 'clone', auth_url, ROOT], \n",
        "                                  capture_output=True, text=True)\n",
        "            \n",
        "            if result.returncode == 0 and os.path.exists(ROOT):\n",
        "                print(\"Clone th√†nh c√¥ng!\")\n",
        "                os.chdir(ROOT)\n",
        "                \n",
        "                # Chuy·ªÉn v·ªÅ HTTPS URL kh√¥ng c√≥ token ƒë·ªÉ tr√°nh l·ªô\n",
        "                subprocess.run(['git', 'remote', 'set-url', 'origin', REPO_URL], \n",
        "                             capture_output=True)\n",
        "            else:\n",
        "                print(\"Clone th·∫•t b·∫°i!\")\n",
        "                print(\"Error:\", result.stderr)\n",
        "        else:\n",
        "            print(\"Kh√¥ng c√≥ token. Vui l√≤ng cung c·∫•p token ƒë·ªÉ clone repository.\")\n",
        "    else:\n",
        "        print(\"Repository ƒë√£ t·ªìn t·∫°i\")\n",
        "        if os.path.exists(os.path.join(ROOT, \".git\")):\n",
        "            print(\"ƒêang pull updates...\")\n",
        "            os.chdir(ROOT)\n",
        "            result = subprocess.run(['git', 'pull'], capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                print(\"Pull th√†nh c√¥ng!\")\n",
        "            else:\n",
        "                print(\"Pull warning:\", result.stderr)\n",
        "        else:\n",
        "            os.chdir(ROOT)\n",
        "    \n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(\"ƒêang ch·∫°y local, b·ªè qua clone repo\")\n",
        "    if os.path.exists(ROOT):\n",
        "        os.chdir(ROOT)\n",
        "    print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è ƒêang ch·∫°y local, b·ªè qua sync t·ª´ Drive\n"
          ]
        }
      ],
      "source": [
        "# Sync d·ªØ li·ªáu t·ª´ Drive (ch·ªâ tr√™n Colab)\n",
        "if IS_COLAB and DRIVE_ROOT:\n",
        "    import shutil\n",
        "    if os.path.exists(os.path.join(DRIVE_ROOT, \"data\")):\n",
        "        print(\"ƒêang sync d·ªØ li·ªáu t·ª´ Drive...\")\n",
        "        shutil.copytree(os.path.join(DRIVE_ROOT, \"data\"), \n",
        "                        os.path.join(ROOT, \"data\"), \n",
        "                        dirs_exist_ok=True)\n",
        "        print(\"Sync ho√†n t·∫•t\")\n",
        "    else:\n",
        "        print(\"Ch∆∞a c√≥ d·ªØ li·ªáu trong Drive, b·ªè qua sync\")\n",
        "else:\n",
        "    print(\"ƒêang ch·∫°y local, b·ªè qua sync t·ª´ Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è ƒêang ch·∫°y local, b·ªè qua c√†i ƒë·∫∑t dependencies\n",
            "ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t: pip install -r requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (ch·ªâ tr√™n Colab)\n",
        "if IS_COLAB:\n",
        "    print(\"C√†i ƒë·∫∑t PyTorch v√† dependencies...\")\n",
        "    \n",
        "    # G·ª° torchaudio n·∫øu c√≥ conflict\n",
        "    %pip uninstall -y torchaudio\n",
        "    \n",
        "    # C√†i PyTorch\n",
        "    %pip install -q torch==2.5.1+cu118 torchvision==0.20.1+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
        "    \n",
        "    # C√†i c√°c package c∆° b·∫£n (kh√¥ng d√πng requirements.txt ƒë·ªÉ tr√°nh version c≈©)\n",
        "    %pip install -q onnxruntime-gpu insightface\n",
        "    %pip install -q numpy pandas opencv-python-headless Pillow scikit-learn matplotlib tqdm pyyaml\n",
        "    \n",
        "    print(\"Ho√†n t·∫•t c√†i ƒë·∫∑t dependencies!\")\n",
        "else:\n",
        "    print(\"ƒêang ch·∫°y local, b·ªè qua c√†i ƒë·∫∑t dependencies\")\n",
        "    print(\"ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t: pip install -r requirements.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data/checkpoints paths\n",
        "if IS_COLAB and DRIVE_ROOT:\n",
        "    CHECKPOINT_DIR = os.path.join(DRIVE_ROOT, \"models\", \"checkpoints\")\n",
        "    DATA_DIR = os.path.join(DRIVE_ROOT, \"data\")\n",
        "else:\n",
        "    CHECKPOINT_DIR = os.path.join(ROOT, \"models\", \"checkpoints\")\n",
        "    DATA_DIR = os.path.join(ROOT, \"data\")\n",
        "    \n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "print(\"CHECKPOINT_DIR=\", CHECKPOINT_DIR)\n",
        "print(\"DATA_DIR=\", DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch cuda: False\n",
            "  - ‚ö†Ô∏è CUDA kh√¥ng kh·∫£ d·ª•ng, s·∫Ω s·ª≠ d·ª•ng CPU\n",
            "mxnet: ch∆∞a c√†i ƒë·∫∑t (optional)\n",
            "onnxruntime: ch∆∞a c√†i ƒë·∫∑t (optional)\n"
          ]
        }
      ],
      "source": [
        "# Ki·ªÉm tra GPU v√† dependencies\n",
        "import torch\n",
        "print(\"=== GPU INFO ===\")\n",
        "print(f\"torch cuda: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  - CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"  - Device name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  - Device count: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    print(\"  - CUDA kh√¥ng kh·∫£ d·ª•ng, s·∫Ω s·ª≠ d·ª•ng CPU\")\n",
        "\n",
        "print(\"\\n=== DEPENDENCIES ===\")\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "    providers = ort.get_available_providers()\n",
        "    print(f\"onnxruntime: OK (providers: {providers})\")\n",
        "except ImportError:\n",
        "    print(\"onnxruntime: ch∆∞a c√†i ƒë·∫∑t\")\n",
        "\n",
        "try:\n",
        "    import insightface\n",
        "    print(f\"insightface: OK (version: {insightface.__version__})\")\n",
        "except ImportError:\n",
        "    print(\"insightface: ch∆∞a c√†i ƒë·∫∑t\")\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    print(f\"opencv: OK\")\n",
        "except ImportError:\n",
        "    print(\"opencv: ch∆∞a c√†i ƒë·∫∑t\")\n",
        "\n",
        "print(\"\\nS·∫µn s√†ng ƒë·ªÉ training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHECKPOINT_DIR= /content/models/checkpoints\n",
            "DATA_DIR= /content/data\n"
          ]
        }
      ],
      "source": [
        "# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n v√† ki·ªÉm tra files\n",
        "CONFIG_PATH = os.path.join(ROOT, \"configs\", \"arcface_config.yaml\")\n",
        "TRAIN_SCRIPT = os.path.join(ROOT, \"models\", \"arcface\", \"train_arcface.py\")\n",
        "PRETRAINED_BACKBONE = os.path.join(CHECKPOINT_DIR, \"ms1mv2_resnet50.pth\")\n",
        "\n",
        "# Data paths (t·ª´ config ho·∫∑c default)\n",
        "train_csv_path = os.path.join(DATA_DIR, \"processed\", \"train_metadata.csv\")\n",
        "val_csv_path = os.path.join(DATA_DIR, \"processed\", \"val_metadata.csv\")\n",
        "\n",
        "print(\"=== FILE PATHS ===\")\n",
        "print(f\"CONFIG_PATH: {CONFIG_PATH}\")\n",
        "print(f\"  Exists: {os.path.exists(CONFIG_PATH)}\")\n",
        "print(f\"\\nTRAIN_SCRIPT: {TRAIN_SCRIPT}\")\n",
        "print(f\"  Exists: {os.path.exists(TRAIN_SCRIPT)}\")\n",
        "print(f\"\\nPRETRAINED_BACKBONE: {PRETRAINED_BACKBONE}\")\n",
        "print(f\"  Exists: {os.path.exists(PRETRAINED_BACKBONE)}\")\n",
        "print(f\"\\nDATA_DIR: {DATA_DIR}\")\n",
        "print(f\"  Exists: {os.path.exists(DATA_DIR)}\")\n",
        "print(f\"\\nTrain CSV: {train_csv_path}\")\n",
        "print(f\"  Exists: {os.path.exists(train_csv_path)}\")\n",
        "print(f\"\\nVal CSV: {val_csv_path}\")\n",
        "print(f\"  Exists: {os.path.exists(val_csv_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== N·ªôi dung ROOT ===\n",
            "ROOT: /content\n",
            "Found 6 items:\n",
            "  - .config\n",
            "  - FaceRecognition\n",
            "  - data\n",
            "  - drive\n",
            "  - models\n",
            "  - sample_data\n",
            "\n",
            "=== File Paths ===\n",
            "CONFIG_PATH: /content/configs/arcface_config.yaml\n",
            "Config exists: False\n",
            "PRETRAINED: /content/models/checkpoints/ms1mv2_resnet50.pth\n",
            "Pretrained exists: False\n"
          ]
        }
      ],
      "source": [
        "# Ki·ªÉm tra d·ªØ li·ªáu training\n",
        "print(\"=== KI·ªÇM TRA D·ªÆ LI·ªÜU ===\")\n",
        "data_ready = True\n",
        "\n",
        "if not os.path.exists(train_csv_path):\n",
        "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y: {train_csv_path}\")\n",
        "    data_ready = False\n",
        "else:\n",
        "    print(f\"‚úÖ Train CSV: {train_csv_path}\")\n",
        "\n",
        "if not os.path.exists(val_csv_path):\n",
        "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y: {val_csv_path}\")\n",
        "    data_ready = False\n",
        "else:\n",
        "    print(f\"‚úÖ Val CSV: {val_csv_path}\")\n",
        "\n",
        "# Ki·ªÉm tra th∆∞ m·ª•c ·∫£nh\n",
        "train_img_dir = os.path.join(DATA_DIR, \"processed\", \"train\")\n",
        "val_img_dir = os.path.join(DATA_DIR, \"processed\", \"val\")\n",
        "\n",
        "if not os.path.exists(train_img_dir):\n",
        "    print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y: {train_img_dir}\")\n",
        "    print(\"   (C√≥ th·ªÉ ·∫£nh n·∫±m ·ªü ƒë∆∞·ªùng d·∫´n kh√°c, ki·ªÉm tra CSV)\")\n",
        "else:\n",
        "    print(f\"‚úÖ Train images: {train_img_dir}\")\n",
        "\n",
        "if not os.path.exists(val_img_dir):\n",
        "    print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y: {val_img_dir}\")\n",
        "    print(\"   (C√≥ th·ªÉ ·∫£nh n·∫±m ·ªü ƒë∆∞·ªùng d·∫´n kh√°c, ki·ªÉm tra CSV)\")\n",
        "else:\n",
        "    print(f\"‚úÖ Val images: {val_img_dir}\")\n",
        "\n",
        "if data_ready:\n",
        "    print(\"\\n‚úÖ D·ªØ li·ªáu s·∫µn s√†ng cho training!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Thi·∫øu d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KI·ªÇM TRA D·ªÆ LI·ªÜU ===\n",
            "\n",
            "‚ùå Kh√¥ng t√¨m th·∫•y: /content/data/processed/train_metadata.csv\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "‚ùå Kh√¥ng t√¨m th·∫•y: /content/data/processed/val_metadata.csv\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "‚ùå Kh√¥ng t√¨m th·∫•y: /content/data/processed/train\n",
            "‚ùå Kh√¥ng t√¨m th·∫•y: /content/data/processed/val\n"
          ]
        }
      ],
      "source": [
        "# Ch·∫°y training\n",
        "if not os.path.exists(TRAIN_SCRIPT):\n",
        "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y training script: {TRAIN_SCRIPT}\")\n",
        "elif not os.path.exists(CONFIG_PATH):\n",
        "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y config file: {CONFIG_PATH}\")\n",
        "elif not os.path.exists(train_csv_path) or not os.path.exists(val_csv_path):\n",
        "    print(\"‚ùå L·ªói: Thi·∫øu d·ªØ li·ªáu training ho·∫∑c validation\")\n",
        "    print(f\"  - Train CSV: {'‚úÖ OK' if os.path.exists(train_csv_path) else '‚ùå THI·∫æU'}\")\n",
        "    print(f\"  - Val CSV: {'‚úÖ OK' if os.path.exists(val_csv_path) else '‚ùå THI·∫æU'}\")\n",
        "    print(\"\\nüí° Vui l√≤ng ch·∫°y notebook data_preprocessing.ipynb ƒë·ªÉ t·∫°o d·ªØ li·ªáu training tr∆∞·ªõc.\")\n",
        "else:\n",
        "    print(\"=\"*60)\n",
        "    print(\"üöÄ B·∫ÆT ƒê·∫¶U TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Config: {CONFIG_PATH}\")\n",
        "    pretrained_arg = f\"--pretrained_backbone {PRETRAINED_BACKBONE}\" if os.path.exists(PRETRAINED_BACKBONE) else \"\"\n",
        "    print(f\"Pretrained backbone: {PRETRAINED_BACKBONE if os.path.exists(PRETRAINED_BACKBONE) else 'Kh√¥ng c√≥ (s·∫Ω train t·ª´ ƒë·∫ßu)'}\")\n",
        "    print(f\"Data dir: {DATA_DIR}\")\n",
        "    print(f\"Checkpoint dir: {CHECKPOINT_DIR}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    cmd = f\"python {TRAIN_SCRIPT} --config {CONFIG_PATH} {pretrained_arg} --data_dir {DATA_DIR} --checkpoint_dir {CHECKPOINT_DIR}\"\n",
        "    !{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Thi·∫øu training script: /content/models/arcface/train_arcface.py\n"
          ]
        }
      ],
      "source": [
        "# Test model sau khi training\n",
        "checkpoint_path = os.path.join(CHECKPOINT_DIR, \"arcface_best.pth\")\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"ƒêang test model t·ª´ checkpoint: {checkpoint_path}\")\n",
        "    \n",
        "    import torch\n",
        "    sys.path.insert(0, ROOT)\n",
        "    from models.arcface.arcface_model import ArcFaceModel\n",
        "    \n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    num_classes = checkpoint.get('num_classes', checkpoint.get('config', {}).get('data', {}).get('num_classes', 100))\n",
        "    \n",
        "    model = ArcFaceModel(num_classes=num_classes, embedding_size=512)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Loaded best model - Epoch {checkpoint.get('epoch', 'N/A')}\")\n",
        "    if 'val_acc' in checkpoint:\n",
        "        print(f\"üìä Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
        "    \n",
        "    dummy_input = torch.randn(1, 3, 112, 112)\n",
        "    with torch.no_grad():\n",
        "        embedding = model.extract_features(dummy_input)\n",
        "    \n",
        "    print(f\"üî¢ Embedding shape: {embedding.shape}\")\n",
        "    print(\"‚úÖ Model s·∫µn s√†ng cho inference!\")\n",
        "else:\n",
        "    print(f\"‚ùå Ch∆∞a c√≥ checkpoint: {checkpoint_path}\")\n",
        "    print(\"üí° Vui l√≤ng ch·∫°y training tr∆∞·ªõc.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models.arcface'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3798351649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marcface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marcface_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing ArcFace Model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.arcface'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
