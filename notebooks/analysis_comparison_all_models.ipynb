{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# So Sanh Tong Hop 3 Mo Hinh: LBPH, FaceNet, ArcFace\n", "\n", "Notebook so sanh hieu nang cua 3 mo hinh face recognition."]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from pathlib import Path\n", "from IPython.display import display, Markdown\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "plt.style.use('seaborn-v0_8-whitegrid')\n", "plt.rcParams['figure.figsize'] = (12, 6)"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Load Data tu 3 Models"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOGS_BASE = Path('../logs')\n", "\n", "with open(LOGS_BASE / 'arcface/training_history.json', 'r') as f:\n", "    arcface_train = json.load(f)\n", "with open(LOGS_BASE / 'arcface/evaluation_report_v2.json', 'r') as f:\n", "    arcface_eval = json.load(f)\n", "\n", "with open(LOGS_BASE / 'facenet/training_history.json', 'r') as f:\n", "    facenet_train = json.load(f)\n", "with open(LOGS_BASE / 'facenet/facenet_evaluation_report.json', 'r') as f:\n", "    facenet_eval = json.load(f)\n", "\n", "with open(LOGS_BASE / 'LBHP/metadata.json', 'r') as f:\n", "    lbph_meta = json.load(f)\n", "\n", "print('Data loaded successfully!')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Bang So Sanh Metrics"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["comparison_data = {\n", "    'Model': ['LBPH', 'FaceNet', 'ArcFace'],\n", "    'Type': ['Traditional ML', 'Deep Learning', 'Deep Learning'],\n", "    'Embedding Size': ['-', 128, 512],\n", "    'Top-1 Accuracy (%)': [lbph_meta['test_accuracy']*100, facenet_eval['metrics']['top1_accuracy'], arcface_eval['metrics']['top1_accuracy']],\n", "    'Top-5 Accuracy (%)': ['-', facenet_eval['metrics']['top5_accuracy'], arcface_eval['metrics']['top5_accuracy']],\n", "    'AUC-ROC': ['-', facenet_eval['metrics']['auc'], arcface_eval['metrics']['auc']],\n", "    'EER (%)': ['-', facenet_eval['metrics']['eer']*100, arcface_eval['metrics']['eer']*100]\n", "}\n", "df = pd.DataFrame(comparison_data)\n", "display(df)"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Bieu Do So Sanh"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n", "\n", "models = ['LBPH', 'FaceNet', 'ArcFace']\n", "top1_acc = [lbph_meta['test_accuracy']*100, facenet_eval['metrics']['top1_accuracy'], arcface_eval['metrics']['top1_accuracy']]\n", "colors = ['#95a5a6', '#e74c3c', '#2ecc71']\n", "\n", "bars = axes[0].bar(models, top1_acc, color=colors, edgecolor='black')\n", "axes[0].set_ylabel('Accuracy (%)')\n", "axes[0].set_title('Top-1 Accuracy Comparison')\n", "axes[0].set_ylim([0, 100])\n", "for bar, val in zip(bars, top1_acc):\n", "    axes[0].text(bar.get_x()+bar.get_width()/2, val+2, f'{val:.1f}%', ha='center', fontweight='bold')\n", "\n", "deep_models = ['FaceNet', 'ArcFace']\n", "auc_vals = [facenet_eval['metrics']['auc'], arcface_eval['metrics']['auc']]\n", "eer_vals = [facenet_eval['metrics']['eer']*100, arcface_eval['metrics']['eer']*100]\n", "\n", "x = np.arange(len(deep_models))\n", "width = 0.35\n", "bars1 = axes[1].bar(x - width/2, auc_vals, width, label='AUC', color='#3498db')\n", "bars2 = axes[1].bar(x + width/2, [v/100 for v in eer_vals], width, label='EER', color='#e74c3c')\n", "axes[1].set_ylabel('Score')\n", "axes[1].set_title('AUC vs EER (Deep Learning Models)')\n", "axes[1].set_xticks(x)\n", "axes[1].set_xticklabels(deep_models)\n", "axes[1].legend()\n", "axes[1].set_ylim([0, 1])\n", "\n", "facenet_epochs = list(range(1, len(facenet_train['train_loss']) + 1))\n", "arcface_epochs = list(range(1, len(arcface_train['history']['train_loss']) + 1))\n", "axes[2].plot(facenet_epochs, [x*100 for x in facenet_train['val_acc']], 'r-', lw=2, label='FaceNet')\n", "axes[2].plot(arcface_epochs, arcface_train['history']['val_acc'], 'g-', lw=2, label='ArcFace')\n", "axes[2].axhline(y=lbph_meta['test_accuracy']*100, color='gray', linestyle='--', label='LBPH')\n", "axes[2].set_xlabel('Epoch')\n", "axes[2].set_ylabel('Validation Accuracy (%)')\n", "axes[2].set_title('Training Progress Comparison')\n", "axes[2].legend()\n", "axes[2].grid(True, alpha=0.3)\n", "\n", "plt.tight_layout()\n", "plt.savefig(LOGS_BASE / 'model_comparison.png', dpi=150, bbox_inches='tight')\n", "plt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Radar Chart So Sanh"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categories = ['Top-1 Acc', 'Top-5 Acc', 'AUC', '1-EER', 'Speed']\n", "\n", "lbph_vals = [lbph_meta['test_accuracy'], 0.1, 0.5, 0.5, 1.0]\n", "facenet_vals = [facenet_eval['metrics']['top1_accuracy']/100, facenet_eval['metrics']['top5_accuracy']/100, \n", "                facenet_eval['metrics']['auc'], 1-facenet_eval['metrics']['eer'], 0.8]\n", "arcface_vals = [arcface_eval['metrics']['top1_accuracy']/100, arcface_eval['metrics']['top5_accuracy']/100,\n", "                arcface_eval['metrics']['auc'], 1-arcface_eval['metrics']['eer'], 0.6]\n", "\n", "angles = [n / float(len(categories)) * 2 * np.pi for n in range(len(categories))]\n", "angles += angles[:1]\n", "\n", "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n", "\n", "for vals, name, color in [(lbph_vals, 'LBPH', '#95a5a6'), (facenet_vals, 'FaceNet', '#e74c3c'), (arcface_vals, 'ArcFace', '#2ecc71')]:\n", "    vals = vals + vals[:1]\n", "    ax.plot(angles, vals, 'o-', linewidth=2, label=name, color=color)\n", "    ax.fill(angles, vals, alpha=0.1, color=color)\n", "\n", "ax.set_xticks(angles[:-1])\n", "ax.set_xticklabels(categories)\n", "ax.set_ylim(0, 1)\n", "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1))\n", "ax.set_title('Model Performance Comparison Radar', pad=20)\n", "\n", "plt.tight_layout()\n", "plt.savefig(LOGS_BASE / 'radar_comparison.png', dpi=150, bbox_inches='tight')\n", "plt.show()"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Bao Cao Tong Hop"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["report = f'''\n", "# BAO CAO SO SANH 3 MO HINH FACE RECOGNITION\n", "\n", "## 1. TONG QUAN\n", "\n", "| Model | Type | Embedding | Top-1 Acc | AUC | EER |\n", "|-------|------|-----------|-----------|-----|-----|\n", "| LBPH | Traditional | - | {lbph_meta[\"test_accuracy\"]*100:.2f}% | - | - |\n", "| FaceNet | Deep Learning | 128 | {facenet_eval[\"metrics\"][\"top1_accuracy\"]:.2f}% | {facenet_eval[\"metrics\"][\"auc\"]:.4f} | {facenet_eval[\"metrics\"][\"eer\"]*100:.2f}% |\n", "| ArcFace | Deep Learning | 512 | {arcface_eval[\"metrics\"][\"top1_accuracy\"]:.2f}% | {arcface_eval[\"metrics\"][\"auc\"]:.4f} | {arcface_eval[\"metrics\"][\"eer\"]*100:.2f}% |\n", "\n", "## 2. NHAN XET\n", "\n", "### ArcFace (TOT NHAT)\n", "- Top-1 Accuracy cao nhat: {arcface_eval[\"metrics\"][\"top1_accuracy\"]:.2f}%\n", "- AUC cao nhat: {arcface_eval[\"metrics\"][\"auc\"]:.4f}\n", "- EER thap nhat: {arcface_eval[\"metrics\"][\"eer\"]*100:.2f}%\n", "\n", "### FaceNet\n", "- Top-1 Accuracy: {facenet_eval[\"metrics\"][\"top1_accuracy\"]:.2f}%\n", "- Embedding nho hon (128 vs 512) -> nhanh hon\n", "- EER cao hon ArcFace: {facenet_eval[\"metrics\"][\"eer\"]*100:.2f}%\n", "\n", "### LBPH\n", "- Accuracy rat thap: {lbph_meta[\"test_accuracy\"]*100:.2f}%\n", "- Khong phu hop voi large-scale recognition\n", "- Phu hop cho small-scale applications\n", "\n", "## 3. KET LUAN\n", "\n", "**ArcFace** la mo hinh tot nhat cho bai toan face recognition voi:\n", "- Hieu suat cao nhat tren tat ca metrics\n", "- Phu hop cho production systems\n", "- Trade-off: Yeu cau GPU va thoi gian training lon hon\n", "'''\n", "display(Markdown(report))"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["summary = {\n", "    'comparison_date': '2025-12-20',\n", "    'models': {\n", "        'lbph': {'type': 'Traditional', 'top1': lbph_meta['test_accuracy']*100},\n", "        'facenet': {'type': 'Deep Learning', 'embedding': 128, 'top1': facenet_eval['metrics']['top1_accuracy'], 'auc': facenet_eval['metrics']['auc'], 'eer': facenet_eval['metrics']['eer']},\n", "        'arcface': {'type': 'Deep Learning', 'embedding': 512, 'top1': arcface_eval['metrics']['top1_accuracy'], 'auc': arcface_eval['metrics']['auc'], 'eer': arcface_eval['metrics']['eer']}\n", "    },\n", "    'best_model': 'ArcFace'\n", "}\n", "with open(LOGS_BASE / 'comparison_summary.json', 'w') as f:\n", "    json.dump(summary, f, indent=2)\n", "print('Summary saved!')\n", "print(json.dumps(summary, indent=2))"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10.0"}},
 "nbformat": 4, "nbformat_minor": 4
}
