{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceNet Training - Kaggle\n",
    "\n",
    "Notebook huấn luyện FaceNet trên Kaggle với GPU miễn phí.\n",
    "\n",
    "## Chuẩn bị:\n",
    "1. Upload dataset `CelebA_Aligned_Balanced` lên Kaggle Datasets\n",
    "2. Add dataset vào notebook này\n",
    "3. Bật GPU: Settings > Accelerator > GPU P100/T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect môi trường\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "print(f\"Kaggle environment: {IS_KAGGLE}\")\n",
    "\n",
    "if not IS_KAGGLE:\n",
    "    print(\"WARNING: Notebook này được thiết kế cho Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình đường dẫn Kaggle\n",
    "ROOT = \"/kaggle/working/FaceRecognition\"\n",
    "CHECKPOINT_DIR = \"/kaggle/working/checkpoints/facenet\"\n",
    "\n",
    "# Dataset path - thay đổi theo tên dataset của bạn trên Kaggle\n",
    "KAGGLE_DATASET_NAME = \"celeba-aligned-balanced\"\n",
    "DATA_DIR = f\"/kaggle/input/{KAGGLE_DATASET_NAME}\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ROOT: {ROOT}\")\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"CHECKPOINT_DIR: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CAU HINH CHECKPOINT DATASET ===\n",
    "CHECKPOINT_DATASET_NAME = \"\"\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "if CHECKPOINT_DATASET_NAME:\n",
    "    checkpoint_input_dir = f\"/kaggle/input/{CHECKPOINT_DATASET_NAME}\"\n",
    "    if os.path.exists(checkpoint_input_dir):\n",
    "        print(f\"[OK] Tim thay checkpoint dataset\")\n",
    "        pth_files = glob.glob(os.path.join(checkpoint_input_dir, \"**/*.pth\"), recursive=True)\n",
    "        if pth_files:\n",
    "            os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "            for pth_file in pth_files:\n",
    "                dest_path = os.path.join(CHECKPOINT_DIR, os.path.basename(pth_file))\n",
    "                if not os.path.exists(dest_path):\n",
    "                    shutil.copy(pth_file, dest_path)\n",
    "                    print(f\"[COPY] {os.path.basename(pth_file)}\")\n",
    "else:\n",
    "    print(\"[INFO] Training tu dau (khong co checkpoint)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra Kaggle dataset\n",
    "print(\"=== KAGGLE INPUT DATASETS ===\")\n",
    "!ls -la /kaggle/input/\n",
    "\n",
    "if os.path.exists(DATA_DIR):\n",
    "    print(f\"\\n[OK] Dataset found at: {DATA_DIR}\")\n",
    "    !ls -la {DATA_DIR}\n",
    "else:\n",
    "    print(f\"\\n[ERROR] Dataset not found at: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cau hinh GitHub token\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "    print(\"[OK] Da lay GITHUB_TOKEN\")\n",
    "except Exception as e:\n",
    "    GITHUB_TOKEN = None\n",
    "    print(\"[INFO] Su dung public URL\")\n",
    "\n",
    "if GITHUB_TOKEN:\n",
    "    REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/sin0235/FaceRecognition.git\"\n",
    "else:\n",
    "    REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "if os.path.exists(ROOT):\n",
    "    print(\"Repository da ton tai, dang pull updates...\")\n",
    "    %cd {ROOT}\n",
    "    if GITHUB_TOKEN:\n",
    "        !git remote set-url origin {REPO_URL}\n",
    "    !git pull\n",
    "else:\n",
    "    print(f\"Dang clone repository...\")\n",
    "    !git clone {REPO_URL} {ROOT}\n",
    "    %cd {ROOT}\n",
    "\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm ROOT vào Python path\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "    print(f\"Da them {ROOT} vao Python path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt dependencies (KHONG cai lai torch)\n",
    "print(\"Cai dat dependencies...\")\n",
    "!pip install -q facenet-pytorch --no-deps\n",
    "!pip install -q opencv-python-headless Pillow scikit-learn tqdm pyyaml\n",
    "print(\"\\nHoan tat cai dat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra GPU\n",
    "import torch\n",
    "\n",
    "print(\"=== GPU INFO ===\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra dữ liệu training\n",
    "train_img_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_img_dir = os.path.join(DATA_DIR, \"val\")\n",
    "\n",
    "if not os.path.exists(train_img_dir):\n",
    "    train_img_dir = os.path.join(DATA_DIR, \"CelebA_Aligned_Balanced\", \"train\")\n",
    "    val_img_dir = os.path.join(DATA_DIR, \"CelebA_Aligned_Balanced\", \"val\")\n",
    "\n",
    "print(\"=== KIEM TRA DU LIEU ===\")\n",
    "\n",
    "if os.path.exists(train_img_dir):\n",
    "    train_identities = [d for d in os.listdir(train_img_dir) \n",
    "                        if os.path.isdir(os.path.join(train_img_dir, d))]\n",
    "    print(f\"[OK] Train: {len(train_identities)} identities\")\n",
    "else:\n",
    "    print(f\"[ERROR] Train folder not found\")\n",
    "\n",
    "if os.path.exists(val_img_dir):\n",
    "    val_identities = [d for d in os.listdir(val_img_dir) \n",
    "                      if os.path.isdir(os.path.join(val_img_dir, d))]\n",
    "    print(f\"[OK] Val: {len(val_identities)} identities\")\n",
    "else:\n",
    "    print(f\"[ERROR] Val folder not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "from models.facenet.facenet_model import FaceNetModel, TripletLoss\n",
    "from models.facenet.facenet_dataloader import FaceNetTripletDataset\n",
    "\n",
    "print(\"[OK] Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config từ file YAML\n",
    "CONFIG_PATH = os.path.join(ROOT, \"configs/facenet_kaggle.yaml\")\n",
    "\n",
    "with open(CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Loaded config from: {CONFIG_PATH}\")\n",
    "\n",
    "# Extract config values\n",
    "model_cfg = config['model']\n",
    "train_cfg = config['training']\n",
    "data_cfg = config['dataset']\n",
    "\n",
    "BATCH_SIZE = train_cfg['batch_size']\n",
    "NUM_EPOCHS = train_cfg['num_epochs']\n",
    "LEARNING_RATE = train_cfg['learning_rate']\n",
    "MARGIN = model_cfg['margin']\n",
    "EMBEDDING_SIZE = model_cfg['embedding_size']\n",
    "IMAGE_SIZE = data_cfg['image_size']\n",
    "PATIENCE = train_cfg['patience']\n",
    "NUM_WORKERS = train_cfg.get('num_workers', 4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "print(f\"\\n=== CONFIG ===\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Margin: {MARGIN}\")\n",
    "print(f\"Embedding size: {EMBEDDING_SIZE}\")\n",
    "print(f\"Image size: {IMAGE_SIZE}\")\n",
    "print(f\"Patience: {PATIENCE}\")\n",
    "print(f\"Num workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataLoader\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "train_dataset = FaceNetTripletDataset(\n",
    "    root_dir=train_img_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    augment=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataset = FaceNetTripletDataset(\n",
    "    root_dir=val_img_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    augment=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train identities: {len(train_dataset.identities)}\")\n",
    "print(f\"Val identities: {len(val_dataset.identities)}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo model\n",
    "print(\"Creating model...\")\n",
    "\n",
    "model = FaceNetModel(\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    pretrained='vggface2',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "\n",
    "criterion = TripletLoss(margin=MARGIN)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=train_cfg.get('weight_decay', 0.0001)\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=train_cfg.get('scheduler_step', 10),\n",
    "    gamma=train_cfg.get('scheduler_gamma', 0.1)\n",
    ")\n",
    "\n",
    "print(\"Model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def compute_triplet_metrics(anchor_emb, positive_emb, negative_emb):\n",
    "    pos_dist = torch.norm(anchor_emb - positive_emb, p=2, dim=1)\n",
    "    neg_dist = torch.norm(anchor_emb - negative_emb, p=2, dim=1)\n",
    "    correct = (pos_dist < neg_dist).float().sum()\n",
    "    return {\n",
    "        'accuracy': (correct / anchor_emb.size(0)).item(),\n",
    "        'pos_dist': pos_dist.mean().item(),\n",
    "        'neg_dist': neg_dist.mean().item()\n",
    "    }\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0.0, 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch} [Train]\")\n",
    "    for anchor, positive, negative in pbar:\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        emb_a = model(anchor)\n",
    "        emb_p = model(positive)\n",
    "        emb_n = model(negative)\n",
    "\n",
    "        loss = criterion(emb_a, emb_p, emb_n)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics = compute_triplet_metrics(emb_a, emb_p, emb_n)\n",
    "        total_loss += loss.item()\n",
    "        total_acc += metrics['accuracy']\n",
    "        num_batches += 1\n",
    "\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f\"{metrics['accuracy']:.4f}\"})\n",
    "\n",
    "    return total_loss / num_batches, total_acc / num_batches\n",
    "\n",
    "def validate(model, loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0.0, 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch} [Val]\")\n",
    "        for anchor, positive, negative in pbar:\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            emb_a = model(anchor)\n",
    "            emb_p = model(positive)\n",
    "            emb_n = model(negative)\n",
    "\n",
    "            loss = criterion(emb_a, emb_p, emb_n)\n",
    "            metrics = compute_triplet_metrics(emb_a, emb_p, emb_n)\n",
    "            total_loss += loss.item()\n",
    "            total_acc += metrics['accuracy']\n",
    "            num_batches += 1\n",
    "\n",
    "            pbar.set_postfix({'val_loss': f'{loss.item():.4f}', 'val_acc': f\"{metrics['accuracy']:.4f}\"})\n",
    "\n",
    "    return total_loss / num_batches, total_acc / num_batches\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"=\"*60)\n",
    "print(\"BAT DAU TRAINING FACENET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch\n",
    "    )\n",
    "    \n",
    "    val_loss, val_acc = validate(\n",
    "        model, val_loader, criterion, device, epoch\n",
    "    )\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(float(train_loss))\n",
    "    history['train_acc'].append(float(train_acc))\n",
    "    history['val_loss'].append(float(val_loss))\n",
    "    history['val_acc'].append(float(val_acc))\n",
    "    history['lr'].append(float(current_lr))\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"  LR: {current_lr:.6f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        \n",
    "        best_path = os.path.join(CHECKPOINT_DIR, \"facenet_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'config': config\n",
    "        }, best_path)\n",
    "        print(f\"  [SAVED] Best model (val_acc: {val_acc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  Patience: {patience_counter}/{PATIENCE}\")\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\n[EARLY STOPPING] Triggered at epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "total_time = time.time() - training_start\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total time: {total_time/60:.2f} minutes\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu checkpoint cuối và history\n",
    "last_path = os.path.join(CHECKPOINT_DIR, \"facenet_last.pth\")\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'val_acc': val_acc,\n",
    "    'val_loss': val_loss,\n",
    "    'config': config\n",
    "}, last_path)\n",
    "print(f\"Last checkpoint: {last_path}\")\n",
    "\n",
    "history_path = os.path.join(CHECKPOINT_DIR, \"training_history.json\")\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f\"History: {history_path}\")\n",
    "\n",
    "print(f\"\\nCheckpoint files:\")\n",
    "!ls -la {CHECKPOINT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['val_acc'], label='Val')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(history['lr'])\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('LR')\n",
    "axes[2].set_title('Learning Rate')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_curves.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị checkpoint files\n",
    "print(\"=== CHECKPOINT FILES ===\")\n",
    "!ls -lh {CHECKPOINT_DIR}\n",
    "\n",
    "print(\"\\n=== Download ===\")\n",
    "print(f\"Best model: {CHECKPOINT_DIR}/facenet_best.pth\")\n",
    "print(f\"Last model: {CHECKPOINT_DIR}/facenet_last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip checkpoint folder de tai ve\n",
    "import shutil\n",
    "\n",
    "zip_name = \"facenet_checkpoints\"\n",
    "zip_path = f\"/kaggle/working/{zip_name}\"\n",
    "\n",
    "shutil.make_archive(zip_path, \"zip\", CHECKPOINT_DIR)\n",
    "\n",
    "print(f\"[OK] Da tao file zip: {zip_path}.zip\")\n",
    "print(f\"\\nDownload file nay tu panel Output ben phai.\")\n",
    "!ls -lh /kaggle/working/*.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}