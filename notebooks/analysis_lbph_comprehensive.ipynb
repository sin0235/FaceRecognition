{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân Tích Toàn Diện LBPH Model\n",
    "\n",
    "Notebook này thực hiện phân tích và trực quan hóa toàn bộ kết quả training và đánh giá của mô hình LBPH.\n",
    "\n",
    "## Nội dung:\n",
    "1. **Model Configuration**: Cấu hình mô hình LBPH\n",
    "2. **Threshold Analysis**: Phân tích ngưỡng quyết định\n",
    "3. **Confidence Distribution**: Phân bố độ tin cậy\n",
    "4. **Evaluation Metrics**: Độ chính xác và Coverage\n",
    "5. **Confusion Matrix**: Ma trận nhầm lẫn\n",
    "6. **Predictions Analysis**: Phân tích kết quả dự đoán\n",
    "7. **Comprehensive Summary**: Báo cáo tổng hợp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup và Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "LOGS_DIR = Path('../logs/LBHP')\n",
    "print(f\"Logs directory: {LOGS_DIR.absolute()}\")\n",
    "print(f\"\\nCác file có sẵn:\")\n",
    "for f in sorted(LOGS_DIR.glob('*')):\n",
    "    if f.is_file():\n",
    "        print(f\"  - {f.name} ({f.stat().st_size / 1024:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  - {f.name}/ (directory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dữ Liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOGS_DIR / 'metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "with open(LOGS_DIR / 'lbph_evaluation_report.json', 'r') as f:\n",
    "    eval_report = json.load(f)\n",
    "\n",
    "with open(LOGS_DIR / 'confidence_stats.json', 'r') as f:\n",
    "    confidence_stats = json.load(f)\n",
    "\n",
    "with open(LOGS_DIR / 'threshold_history.json', 'r') as f:\n",
    "    threshold_history = json.load(f)\n",
    "\n",
    "predictions_df = pd.read_csv(LOGS_DIR / 'lbph_predictions.csv')\n",
    "threshold_results_df = pd.read_csv(LOGS_DIR / 'lbph_threshold_results.csv')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Number of classes: {metadata['num_classes']}\")\n",
    "print(f\"Train images: {metadata['train_images']}\")\n",
    "print(f\"Val images: {metadata['val_images']}\")\n",
    "print(f\"Test images: {metadata['test_images']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 1: CẤU HÌNH MÔ HÌNH\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('                    LBPH MODEL CONFIGURATION')\n",
    "print('='*70)\n",
    "params = metadata['model_params']\n",
    "print(f'\\n  Model: Local Binary Pattern Histogram (LBPH)')\n",
    "print(f'  Method: {eval_report[\"method\"]}')\n",
    "print(f'\\n  LBPH Parameters:')\n",
    "print(f'    - Radius: {params[\"radius\"]}')\n",
    "print(f'    - Neighbors: {params[\"neighbors\"]}')\n",
    "print(f'    - Grid X: {params[\"grid_x\"]}')\n",
    "print(f'    - Grid Y: {params[\"grid_y\"]}')\n",
    "print(f'\\n  Dataset:')\n",
    "print(f'    - Number of Classes: {metadata[\"num_classes\"]}')\n",
    "print(f'    - Train Images: {metadata[\"train_images\"]}')\n",
    "print(f'    - Validation Images: {metadata[\"val_images\"]}')\n",
    "print(f'    - Test Images: {metadata[\"test_images\"]}')\n",
    "print(f'\\n  Optimal Threshold: {eval_report[\"optimal_threshold\"]}')\n",
    "print(f'  Max Images Per Identity: {eval_report[\"max_images_per_identity\"]}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "param_names = ['Radius', 'Neighbors', 'Grid X', 'Grid Y']\n",
    "param_values = [params['radius'], params['neighbors'], params['grid_x'], params['grid_y']]\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
    "\n",
    "bars = ax.bar(param_names, param_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('LBPH Model Parameters', fontweight='bold', fontsize=14)\n",
    "\n",
    "for bar, val in zip(bars, param_values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, str(val),\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'model_params_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 2: PHÂN TÍCH NGƯỠNG\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_df = pd.DataFrame(threshold_history)\n",
    "print(\"Threshold History:\")\n",
    "display(th_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(th_df['threshold'], th_df['accuracy']*100, 'b-o', lw=2, markersize=8, label='Accuracy')\n",
    "ax1.axvline(x=eval_report['optimal_threshold'], color='red', linestyle='--', lw=2, label=f'Optimal ({eval_report[\"optimal_threshold\"]})')\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title('Accuracy vs Threshold', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(th_df['threshold'], th_df['coverage']*100, 'g-s', lw=2, markersize=8, label='Coverage')\n",
    "ax2.axvline(x=eval_report['optimal_threshold'], color='red', linestyle='--', lw=2, label=f'Optimal ({eval_report[\"optimal_threshold\"]})')\n",
    "ax2.set_xlabel('Threshold')\n",
    "ax2.set_ylabel('Coverage (%)')\n",
    "ax2.set_title('Coverage vs Threshold', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(th_df['threshold'], th_df['accuracy']*100, 'b-o', lw=2, markersize=6, label='Accuracy')\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.plot(th_df['threshold'], th_df['coverage']*100, 'g-s', lw=2, markersize=6, label='Coverage')\n",
    "ax3.axvline(x=eval_report['optimal_threshold'], color='red', linestyle='--', lw=2, alpha=0.7)\n",
    "ax3.set_xlabel('Threshold')\n",
    "ax3.set_ylabel('Accuracy (%)', color='blue')\n",
    "ax3_twin.set_ylabel('Coverage (%)', color='green')\n",
    "ax3.set_title('Accuracy vs Coverage Trade-off', fontweight='bold')\n",
    "ax3.tick_params(axis='y', labelcolor='blue')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='green')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(th_df['threshold'], th_df['score']*100, 'm-^', lw=2, markersize=8, label='Score (Acc × Coverage)')\n",
    "optimal_idx = th_df['score'].idxmax()\n",
    "ax4.scatter([th_df.loc[optimal_idx, 'threshold']], [th_df.loc[optimal_idx, 'score']*100], \n",
    "            color='red', s=200, zorder=5, marker='*', label=f'Best Score')\n",
    "ax4.set_xlabel('Threshold')\n",
    "ax4.set_ylabel('Score (%)')\n",
    "ax4.set_title('Combined Score vs Threshold', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'threshold_analysis_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOptimal Threshold Analysis:\")\n",
    "print(f\"  Best Threshold: {eval_report['optimal_threshold']}\")\n",
    "print(f\"  Best Score: {th_df['score'].max()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Threshold Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_th_df = pd.DataFrame(eval_report['threshold_results'])\n",
    "print(\"Evaluation Threshold Results:\")\n",
    "display(eval_th_df)\n",
    "\n",
    "best_idx = eval_th_df['score'].idxmax()\n",
    "print(f\"\\nBest configuration:\")\n",
    "print(f\"  Threshold: {eval_th_df.loc[best_idx, 'threshold']}\")\n",
    "print(f\"  Accuracy: {eval_th_df.loc[best_idx, 'accuracy']*100:.2f}%\")\n",
    "print(f\"  Coverage: {eval_th_df.loc[best_idx, 'coverage']*100:.2f}%\")\n",
    "print(f\"  Score: {eval_th_df.loc[best_idx, 'score']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 3: PHÂN BỐ ĐỘ TIN CẬY\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confidence Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('                 CONFIDENCE STATISTICS')\n",
    "print('='*70)\n",
    "print(f'\\n  CORRECT Predictions:')\n",
    "print(f'    - Count: {confidence_stats[\"correct\"][\"count\"]}')\n",
    "print(f'    - Mean Distance: {confidence_stats[\"correct\"][\"mean\"]:.2f}')\n",
    "print(f'    - Std: {confidence_stats[\"correct\"][\"std\"]:.2f}')\n",
    "print(f'    - Min: {confidence_stats[\"correct\"][\"min\"]:.2f}')\n",
    "print(f'    - Max: {confidence_stats[\"correct\"][\"max\"]:.2f}')\n",
    "print(f'    - Median: {confidence_stats[\"correct\"][\"median\"]:.2f}')\n",
    "print(f'\\n  INCORRECT Predictions:')\n",
    "print(f'    - Count: {confidence_stats[\"incorrect\"][\"count\"]}')\n",
    "print(f'    - Mean Distance: {confidence_stats[\"incorrect\"][\"mean\"]:.2f}')\n",
    "print(f'    - Std: {confidence_stats[\"incorrect\"][\"std\"]:.2f}')\n",
    "print(f'    - Min: {confidence_stats[\"incorrect\"][\"min\"]:.2f}')\n",
    "print(f'    - Max: {confidence_stats[\"incorrect\"][\"max\"]:.2f}')\n",
    "print(f'    - Median: {confidence_stats[\"incorrect\"][\"median\"]:.2f}')\n",
    "print(f'\\n  Threshold Used: {confidence_stats[\"threshold\"]}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "cm = confidence_stats['correct']['mean']\n",
    "cs = confidence_stats['correct']['std']\n",
    "im = confidence_stats['incorrect']['mean']\n",
    "ist = confidence_stats['incorrect']['std']\n",
    "\n",
    "x = np.linspace(0, 150, 500)\n",
    "yc = (1/(cs*np.sqrt(2*np.pi))) * np.exp(-0.5*((x-cm)/cs)**2)\n",
    "yi = (1/(ist*np.sqrt(2*np.pi))) * np.exp(-0.5*((x-im)/ist)**2)\n",
    "\n",
    "ax1.fill_between(x, yc, alpha=0.5, color='green', label=f'Correct (μ={cm:.1f})')\n",
    "ax1.fill_between(x, yi, alpha=0.5, color='red', label=f'Incorrect (μ={im:.1f})')\n",
    "ax1.axvline(x=confidence_stats['threshold'], color='black', linestyle='--', lw=2, label=f'Threshold ({confidence_stats[\"threshold\"]})')\n",
    "ax1.set_xlabel('Distance')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Distance Distribution (Gaussian Approximation)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "categories = ['Correct', 'Incorrect']\n",
    "means = [cm, im]\n",
    "stds = [cs, ist]\n",
    "colors_bar = ['#2ecc71', '#e74c3c']\n",
    "bars = ax2.bar(categories, means, yerr=stds, color=colors_bar, edgecolor='black', \n",
    "               capsize=10, linewidth=1.5, alpha=0.8)\n",
    "ax2.axhline(y=confidence_stats['threshold'], color='black', linestyle='--', lw=2, \n",
    "            label=f'Threshold ({confidence_stats[\"threshold\"]})')\n",
    "ax2.set_ylabel('Mean Distance')\n",
    "ax2.set_title('Mean Distance by Prediction Type', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val, std in zip(bars, means, stds):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 2, f'{val:.1f}',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax3 = axes[2]\n",
    "counts = [confidence_stats['correct']['count'], confidence_stats['incorrect']['count']]\n",
    "explode = (0.02, 0.02)\n",
    "ax3.pie(counts, explode=explode, labels=['Correct', 'Incorrect'], colors=colors_bar,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 11})\n",
    "ax3.set_title('Prediction Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'confidence_analysis_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Existing Confidence Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_dir = LOGS_DIR / 'plots'\n",
    "if plots_dir.exists():\n",
    "    print(\"Existing Visualization Plots:\")\n",
    "    for img_path in sorted(plots_dir.glob('*.png')):\n",
    "        print(f\"\\n--- {img_path.name} ---\")\n",
    "        display(Image(filename=str(img_path), width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 4: ĐÁNH GIÁ MÔ HÌNH\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = eval_report['metrics']\n",
    "timing = eval_report['timing']\n",
    "\n",
    "print('='*70)\n",
    "print('                    LBPH EVALUATION SUMMARY')\n",
    "print('='*70)\n",
    "print(f'\\n  Model: {eval_report[\"model\"]}')\n",
    "print(f'  Optimal Threshold: {eval_report[\"optimal_threshold\"]}')\n",
    "print(f'  Evaluation Timestamp: {eval_report[\"timestamp\"]}')\n",
    "print('\\n' + '-'*70)\n",
    "print('  TEST METRICS:')\n",
    "print('-'*70)\n",
    "print(f'  Test Accuracy: {metrics[\"test_accuracy\"]*100:.2f}%')\n",
    "print(f'  Test Coverage: {metrics[\"test_coverage\"]*100:.2f}%')\n",
    "print(f'  Used Samples: {metrics[\"test_used_samples\"]}/{metrics[\"test_total_samples\"]}')\n",
    "print('\\n' + '-'*70)\n",
    "print('  TIMING:')\n",
    "print('-'*70)\n",
    "print(f'  Threshold Search: {timing[\"threshold_search_seconds\"]:.2f} seconds')\n",
    "print(f'  Test Evaluation: {timing[\"test_eval_seconds\"]:.2f} seconds')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "metric_names = ['Accuracy', 'Coverage']\n",
    "metric_values = [metrics['test_accuracy']*100, metrics['test_coverage']*100]\n",
    "colors = ['#3498db', '#2ecc71']\n",
    "bars = ax1.bar(metric_names, metric_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_ylim([0, 105])\n",
    "ax1.set_ylabel('Value (%)')\n",
    "ax1.set_title('Test Metrics', fontweight='bold')\n",
    "for bar, val in zip(bars, metric_values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{val:.2f}%',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "sizes = [metrics['test_used_samples'], metrics['test_total_samples'] - metrics['test_used_samples']]\n",
    "labels = ['Used', 'Rejected']\n",
    "colors_pie = ['#2ecc71', '#e74c3c']\n",
    "explode = (0.02, 0.05)\n",
    "ax2.pie(sizes, explode=explode, labels=labels, colors=colors_pie, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, textprops={'fontsize': 11})\n",
    "ax2.set_title(f'Sample Coverage ({metrics[\"test_used_samples\"]}/{metrics[\"test_total_samples\"]})', fontweight='bold')\n",
    "\n",
    "ax3 = axes[2]\n",
    "categories = ['Accuracy', 'Coverage', 'Score']\n",
    "score = metrics['test_accuracy'] * metrics['test_coverage']\n",
    "values = [\n",
    "    metrics['test_accuracy'],\n",
    "    metrics['test_coverage'],\n",
    "    score\n",
    "]\n",
    "angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
    "values_radar = values + [values[0]]\n",
    "angles += angles[:1]\n",
    "ax3 = plt.subplot(133, polar=True)\n",
    "ax3.plot(angles, values_radar, 'o-', linewidth=2, color='#3498db')\n",
    "ax3.fill(angles, values_radar, alpha=0.25, color='#3498db')\n",
    "ax3.set_xticks(angles[:-1])\n",
    "ax3.set_xticklabels(categories)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.set_title('Performance Radar', fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOGS_DIR / 'metrics_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_img_path = LOGS_DIR / 'lbph_confusion_matrix.png'\n",
    "if cm_img_path.exists():\n",
    "    print(\"Confusion Matrix (Test Set):\")\n",
    "    display(Image(filename=str(cm_img_path), width=700))\n",
    "else:\n",
    "    print(\"Confusion matrix image not found.\")\n",
    "\n",
    "cm_val_path = LOGS_DIR / 'plots' / 'confusion_matrix_val.png'\n",
    "if cm_val_path.exists():\n",
    "    print(\"\\nConfusion Matrix (Validation Set):\")\n",
    "    display(Image(filename=str(cm_val_path), width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Threshold Analysis Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_img_path = LOGS_DIR / 'lbph_threshold_analysis.png'\n",
    "if th_img_path.exists():\n",
    "    print(\"Threshold Analysis:\")\n",
    "    display(Image(filename=str(th_img_path), width=700))\n",
    "else:\n",
    "    print(\"Threshold analysis image not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 5: PHÂN TÍCH DỰ ĐOÁN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predictions DataFrame Shape: {predictions_df.shape}\")\n",
    "print(f\"\\nColumns: {list(predictions_df.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "display(predictions_df.head(10))\n",
    "\n",
    "print(f\"\\nDataFrame Statistics:\")\n",
    "display(predictions_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'distance' in predictions_df.columns or 'confidence' in predictions_df.columns:\n",
    "    dist_col = 'distance' if 'distance' in predictions_df.columns else 'confidence'\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(predictions_df[dist_col], bins=50, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "    ax1.axvline(x=predictions_df[dist_col].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {predictions_df[dist_col].mean():.2f}')\n",
    "    ax1.axvline(x=eval_report['optimal_threshold'], color='green', linestyle='--',\n",
    "                label=f'Threshold: {eval_report[\"optimal_threshold\"]}')\n",
    "    ax1.set_xlabel('Distance/Confidence')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Prediction Distances', fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    if 'correct' in predictions_df.columns:\n",
    "        ax2 = axes[1]\n",
    "        correct_vals = predictions_df[predictions_df['correct'] == True][dist_col]\n",
    "        incorrect_vals = predictions_df[predictions_df['correct'] == False][dist_col]\n",
    "        ax2.hist(correct_vals, bins=30, color='green', alpha=0.6, label=f'Correct (n={len(correct_vals)})')\n",
    "        ax2.hist(incorrect_vals, bins=30, color='red', alpha=0.6, label=f'Incorrect (n={len(incorrect_vals)})')\n",
    "        ax2.axvline(x=eval_report['optimal_threshold'], color='black', linestyle='--',\n",
    "                    label=f'Threshold: {eval_report[\"optimal_threshold\"]}')\n",
    "        ax2.set_xlabel('Distance/Confidence')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Distance by Prediction Correctness', fontweight='bold')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(LOGS_DIR / 'predictions_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Distance column not found in predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PHẦN 6: BÁO CÁO TỔNG HỢP\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comprehensive Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'model': 'LBPH',\n",
    "    'params': metadata['model_params'],\n",
    "    'num_classes': metadata['num_classes'],\n",
    "    'train_images': metadata['train_images'],\n",
    "    'val_images': metadata['val_images'],\n",
    "    'test_images': metadata['test_images'],\n",
    "    'optimal_threshold': eval_report['optimal_threshold'],\n",
    "    'test_accuracy': metrics['test_accuracy'] * 100,\n",
    "    'test_coverage': metrics['test_coverage'] * 100,\n",
    "    'combined_score': metrics['test_accuracy'] * metrics['test_coverage'] * 100,\n",
    "    'correct_mean_distance': confidence_stats['correct']['mean'],\n",
    "    'incorrect_mean_distance': confidence_stats['incorrect']['mean'],\n",
    "    'distance_separation': confidence_stats['incorrect']['mean'] - confidence_stats['correct']['mean']\n",
    "}\n",
    "\n",
    "with open(LOGS_DIR / 'comprehensive_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('='*70)\n",
    "print('                 COMPREHENSIVE SUMMARY REPORT')\n",
    "print('='*70)\n",
    "print(json.dumps(summary, indent=2))\n",
    "print('='*70)\n",
    "print(f'\\nSummary saved to: {LOGS_DIR / \"comprehensive_summary.json\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('                    PERFORMANCE ASSESSMENT')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n1. RECOGNITION PERFORMANCE:')\n",
    "acc = metrics['test_accuracy'] * 100\n",
    "if acc >= 50:\n",
    "    print(f'   [GOOD] Test Accuracy: {acc:.2f}%')\n",
    "elif acc >= 20:\n",
    "    print(f'   [FAIR] Test Accuracy: {acc:.2f}%')\n",
    "else:\n",
    "    print(f'   [NEEDS IMPROVEMENT] Test Accuracy: {acc:.2f}%')\n",
    "    print(f'   Note: Low accuracy is expected for LBPH with large number of classes ({metadata[\"num_classes\"]})')\n",
    "\n",
    "print('\\n2. COVERAGE:')\n",
    "cov = metrics['test_coverage'] * 100\n",
    "if cov >= 90:\n",
    "    print(f'   [EXCELLENT] Coverage: {cov:.2f}%')\n",
    "elif cov >= 70:\n",
    "    print(f'   [GOOD] Coverage: {cov:.2f}%')\n",
    "else:\n",
    "    print(f'   [NEEDS IMPROVEMENT] Coverage: {cov:.2f}%')\n",
    "\n",
    "print('\\n3. DISTANCE SEPARATION:')\n",
    "separation = summary['distance_separation']\n",
    "if separation >= 30:\n",
    "    print(f'   [EXCELLENT] Distance Separation: {separation:.2f}')\n",
    "    print(f'   (Good separation between correct and incorrect predictions)')\n",
    "elif separation >= 15:\n",
    "    print(f'   [GOOD] Distance Separation: {separation:.2f}')\n",
    "else:\n",
    "    print(f'   [FAIR] Distance Separation: {separation:.2f}')\n",
    "    print(f'   (Overlapping distributions may cause confusion)')\n",
    "\n",
    "print('\\n4. MODEL CHARACTERISTICS:')\n",
    "print(f'   - LBPH is a traditional computer vision method (non-deep learning)')\n",
    "print(f'   - Works well for smaller datasets with controlled conditions')\n",
    "print(f'   - Limited scalability with large number of classes')\n",
    "print(f'   - Fast training and inference')\n",
    "print(f'   - No GPU required')\n",
    "\n",
    "print('\\n5. OVERALL ASSESSMENT:')\n",
    "overall_score = summary['combined_score']\n",
    "print(f'   Combined Score (Acc × Coverage): {overall_score:.2f}%')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Comparison Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('            LBPH vs DEEP LEARNING MODELS')\n",
    "print('='*70)\n",
    "print('''\n",
    "| Aspect              | LBPH                        | FaceNet/ArcFace           |\n",
    "|---------------------|-----------------------------|--------------------------|\n",
    "| Type                | Traditional CV              | Deep Learning            |\n",
    "| Training Speed      | Very Fast                   | Slow (GPU required)      |\n",
    "| Inference Speed     | Fast                        | Moderate                 |\n",
    "| Scalability         | Limited                     | Excellent                |\n",
    "| Large Datasets      | Poor performance            | Excellent performance    |\n",
    "| Feature Learning    | Handcrafted (LBP)           | Learned embeddings       |\n",
    "| Lighting Variations | Sensitive                   | Robust                   |\n",
    "| Pose Variations     | Sensitive                   | Robust                   |\n",
    "| Hardware Required   | CPU only                    | GPU recommended          |\n",
    "''')\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}