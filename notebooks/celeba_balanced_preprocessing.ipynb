{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CelebA Dataset Preprocessing - Xu ly mat can bang\n",
        "\n",
        "**THU TU XU LY DUNG:**\n",
        "1. **Loc bo** identity co 1-4 anh (834 identity)\n",
        "2. **Gom anh** theo identity\n",
        "3. **Alignment TRUOC** - Su dung landmarks goc (QUAN TRONG!)\n",
        "4. **Augmentation SAU** - Ap dung tren anh da align (landmarks da chuan hoa)\n",
        "5. **Chia dataset** theo IDENTITY hoac theo ANH\n",
        "6. **Tao metadata** cho training\n",
        "\n",
        "**Tai sao phai Alignment TRUOC Augmentation?**\n",
        "- Landmarks chi dung cho anh GOC\n",
        "- Sau flip/rotate, vi tri landmarks BI SAI\n",
        "- Align truoc -> augment tren anh 112x112 da chuan -> DUNG!\n",
        "\n",
        "**Files metadata goc:**\n",
        "- `data/meta_origin/identity_CelebA.txt` - Mapping anh -> identity\n",
        "- `data/meta_origin/list_landmarks_align_celeba.csv` - 5 diem landmark (chi dung cho anh goc)\n",
        "- `data/meta_origin/list_attr_celeba.csv` - 40 thuoc tinh\n",
        "- `data/meta_origin/list_bbox_celeba.csv` - Bounding box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cai dat thu vien can thiet\n",
        "%pip install kaggle tqdm opencv-python-headless numpy albumentations scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "DRIVE_OUTPUT = \"/content/drive/MyDrive/FaceRecognition\"\n",
        "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
        "print(f\"Output: {DRIVE_OUTPUT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Kaggle API - THAY DOI KEY CUA BAN\n",
        "import json\n",
        "\n",
        "data = {\n",
        "    \"username\": \"phctontrn\",\n",
        "    \"key\": \"KGAT_bd48d6409aeff2468d3963d28e9d7bcc\"  # Thay doi key cua ban\n",
        "}\n",
        "\n",
        "with open(\"kaggle.json\", \"w\") as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tai dataset CelebA tu Kaggle\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset -p /content/celeba\n",
        "!unzip -q /content/celeba/celeba-dataset.zip -d /content/celeba\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload file identity_CelebA.txt (file nay khong co san trong Kaggle dataset)\n",
        "from google.colab import files\n",
        "print(\"Upload file identity_CelebA.txt:\")\n",
        "uploaded = files.upload()\n",
        "!mv identity_CelebA.txt /content/celeba/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cau hinh xu ly\n",
        "\n",
        "| Tham so | Gia tri | Mo ta |\n",
        "|---------|---------|-------|\n",
        "| MIN_IMAGES | 5 | Loai bo identity co < 5 anh |\n",
        "| AUGMENT_THRESHOLD | 10 | Augment identity co 5-9 anh |\n",
        "| TARGET_MIN_IMAGES | 10 | Muc tieu toi thieu sau augment |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CONFIG - Chon che do COLAB hoac LOCAL\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import albumentations as A\n",
        "from skimage.transform import SimilarityTransform\n",
        "\n",
        "# ============================================================\n",
        "# CHON CHE DO: 'colab' hoac 'local'\n",
        "# ============================================================\n",
        "MODE = 'colab'  # Doi thanh 'local' neu chay tren may tinh ca nhan\n",
        "\n",
        "if MODE == 'colab':\n",
        "    # Paths cho Google Colab - LUU TAM TREN LOCAL COLAB (NHANH)\n",
        "    CELEBA_DIR = \"/content/celeba\"\n",
        "    IMG_DIR = \"/content/celeba/img_align_celeba/img_align_celeba\"\n",
        "    IDENTITY_FILE = \"/content/celeba/identity_CelebA.txt\"\n",
        "    LANDMARK_FILE = \"/content/celeba/list_landmarks_align_celeba.csv\"\n",
        "    TEMP_BY_ID = \"/content/celeba_by_id\"\n",
        "    TEMP_SPLIT = \"/content/celeba_split\"\n",
        "    FINAL_OUTPUT = \"/content/CelebA_Aligned_Balanced\"  # Local Colab - nhanh\n",
        "else:\n",
        "    # Paths cho Local (su dung file meta_origin da co san)\n",
        "    PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(\".\")))\n",
        "    CELEBA_DIR = \"data\"\n",
        "    IMG_DIR = \"data/img_align_celeba\"  # Can download anh rieng\n",
        "    IDENTITY_FILE = \"data/meta_origin/identity_CelebA.txt\"\n",
        "    LANDMARK_FILE = \"data/meta_origin/list_landmarks_align_celeba.csv\"\n",
        "    TEMP_BY_ID = \"data/celeba_by_id\"\n",
        "    TEMP_SPLIT = \"data/celeba_split\"\n",
        "    FINAL_OUTPUT = \"data/CelebA_Aligned_Balanced\"\n",
        "\n",
        "# Filtering parameters\n",
        "MIN_IMAGES = 5          # Loai bo identity < 5 anh\n",
        "AUGMENT_THRESHOLD = 10  # Augment identity co 5-9 anh\n",
        "TARGET_MIN_IMAGES = 10  # Muc tieu toi thieu sau augment\n",
        "\n",
        "# Split ratio - CHIA THEO IDENTITY\n",
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "# Seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ArcFace template 112x112 (5 landmarks)\n",
        "ARCFACE_TEMPLATE = np.array([\n",
        "    [38.2946, 51.6963],   # left_eye\n",
        "    [73.5318, 51.5014],   # right_eye\n",
        "    [56.0252, 71.7366],   # nose\n",
        "    [41.5493, 92.3655],   # left_mouth\n",
        "    [70.7299, 92.2041],   # right_mouth\n",
        "], dtype=np.float32)\n",
        "\n",
        "print(f\"Mode: {MODE}\")\n",
        "print(f\"Identity file: {IDENTITY_FILE}\")\n",
        "print(f\"Output: {FINAL_OUTPUT}\")\n",
        "if MODE == 'colab':\n",
        "    print(f\"ZIP se luu vao Drive: {DRIVE_OUTPUT}\")\n",
        "print(\"Config loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Buoc 1: Phan tich va loc identity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load va phan tich identity\n",
        "identity_df = pd.read_csv(IDENTITY_FILE, sep=\" \", header=None, names=[\"image\", \"identity_id\"])\n",
        "print(f\"Tong so anh: {len(identity_df):,}\")\n",
        "print(f\"Tong so identity: {identity_df['identity_id'].nunique():,}\")\n",
        "\n",
        "# Thong ke so anh moi identity\n",
        "identity_counts = identity_df['identity_id'].value_counts()\n",
        "\n",
        "# Phan loai identity\n",
        "ids_to_remove = identity_counts[identity_counts < MIN_IMAGES].index.tolist()\n",
        "ids_to_augment = identity_counts[(identity_counts >= MIN_IMAGES) & (identity_counts < AUGMENT_THRESHOLD)].index.tolist()\n",
        "ids_normal = identity_counts[identity_counts >= AUGMENT_THRESHOLD].index.tolist()\n",
        "\n",
        "print(f\"\\nPhan loai identity:\")\n",
        "print(f\"  LOAI BO (< {MIN_IMAGES} anh): {len(ids_to_remove):,}\")\n",
        "print(f\"  CAN AUGMENT ({MIN_IMAGES}-{AUGMENT_THRESHOLD-1} anh): {len(ids_to_augment):,}\")\n",
        "print(f\"  BINH THUONG (>= {AUGMENT_THRESHOLD} anh): {len(ids_normal):,}\")\n",
        "\n",
        "removed_images = identity_counts[ids_to_remove].sum()\n",
        "print(f\"\\nSo anh se bi loai: {removed_images:,} ({100*removed_images/len(identity_df):.1f}%)\")\n",
        "\n",
        "# Loc dataset\n",
        "valid_ids = set(ids_to_augment + ids_normal)\n",
        "filtered_df = identity_df[identity_df['identity_id'].isin(valid_ids)].copy()\n",
        "\n",
        "print(f\"\\nSau khi loc:\")\n",
        "print(f\"  - So anh: {len(filtered_df):,}\")\n",
        "print(f\"  - So identity: {filtered_df['identity_id'].nunique():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Buoc 2: Gom anh theo identity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gom anh theo identity (chi anh da loc)\n",
        "os.makedirs(TEMP_BY_ID, exist_ok=True)\n",
        "\n",
        "for _, row in tqdm(filtered_df.iterrows(), total=len(filtered_df), desc=\"Gom anh theo ID\"):\n",
        "    img_file = row['image']\n",
        "    pid = str(row['identity_id'])\n",
        "    \n",
        "    dst_dir = f\"{TEMP_BY_ID}/{pid}\"\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "    \n",
        "    src_path = f\"{IMG_DIR}/{img_file}\"\n",
        "    dst_path = f\"{dst_dir}/{img_file}\"\n",
        "    \n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Buoc 3: Offline Augmentation cho identity it anh (5-9 anh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Augmentation pipeline\n",
        "augment_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=15, p=0.7, border_mode=cv2.BORDER_REPLICATE),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.05, p=0.8),\n",
        "    A.OneOf([\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "        A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
        "    ], p=0.3),\n",
        "])\n",
        "\n",
        "def augment_identity_images(person_dir, target_count):\n",
        "    images = [f for f in os.listdir(person_dir) if f.endswith('.jpg')]\n",
        "    current_count = len(images)\n",
        "    \n",
        "    if current_count >= target_count:\n",
        "        return 0\n",
        "    \n",
        "    needed = target_count - current_count\n",
        "    augmented = 0\n",
        "    \n",
        "    while augmented < needed:\n",
        "        src_img_name = random.choice(images)\n",
        "        src_path = os.path.join(person_dir, src_img_name)\n",
        "        \n",
        "        img = cv2.imread(src_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        \n",
        "        augmented_img = augment_transform(image=img)['image']\n",
        "        \n",
        "        base_name = os.path.splitext(src_img_name)[0]\n",
        "        new_name = f\"{base_name}_aug{augmented+1}.jpg\"\n",
        "        new_path = os.path.join(person_dir, new_name)\n",
        "        \n",
        "        cv2.imwrite(new_path, augmented_img)\n",
        "        augmented += 1\n",
        "    \n",
        "    return augmented\n",
        "\n",
        "# Chay augmentation\n",
        "total_augmented = 0\n",
        "for pid in tqdm(ids_to_augment, desc=\"Augmenting\"):\n",
        "    person_dir = os.path.join(TEMP_BY_ID, str(pid))\n",
        "    if os.path.exists(person_dir):\n",
        "        total_augmented += augment_identity_images(person_dir, TARGET_MIN_IMAGES)\n",
        "\n",
        "print(f\"\\nTong so anh da augment: {total_augmented:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Buoc 4: Chia Train/Val/Test\n",
        "\n",
        "**Chon 1 trong 2 cach:**\n",
        "\n",
        "| Cach | Mo ta | Dung cho |\n",
        "|------|-------|----------|\n",
        "| `split_by_identity` | Moi identity CHI o 1 tap | Face Identification |\n",
        "| `split_by_image` | Moi identity co anh o CA 3 tap | Face Verification |\n",
        "\n",
        "**Mac dinh: `split_by_image`** - Phu hop cho du an nhan dien khuon mat nguoi noi tieng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CHON CACH CHIA: 'by_image' hoac 'by_identity'\n",
        "# ============================================================\n",
        "SPLIT_METHOD = 'by_image'  # 'by_image': moi identity co anh o ca 3 tap\n",
        "                           # 'by_identity': moi identity chi o 1 tap\n",
        "\n",
        "all_ids = sorted([d for d in os.listdir(TEMP_BY_ID) if os.path.isdir(os.path.join(TEMP_BY_ID, d))])\n",
        "print(f\"Tong so identity: {len(all_ids)}\")\n",
        "print(f\"Phuong phap chia: {SPLIT_METHOD}\")\n",
        "\n",
        "# Tao thu muc split\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(os.path.join(TEMP_SPLIT, split), exist_ok=True)\n",
        "\n",
        "stats = {'train': 0, 'val': 0, 'test': 0}\n",
        "identity_stats = {'train': set(), 'val': set(), 'test': set()}\n",
        "\n",
        "if SPLIT_METHOD == 'by_image':\n",
        "    # Chia ANH trong moi identity vao ca 3 tap\n",
        "    # Dam bao moi identity co anh trong TRAIN, VAL, TEST\n",
        "    MIN_IMAGES_FOR_SPLIT = 3  # Can it nhat 3 anh de chia\n",
        "    \n",
        "    for pid in tqdm(all_ids, desc=\"Chia anh theo identity\"):\n",
        "        src_dir = os.path.join(TEMP_BY_ID, pid)\n",
        "        images = [f for f in os.listdir(src_dir) if f.endswith('.jpg')]\n",
        "        \n",
        "        if len(images) < MIN_IMAGES_FOR_SPLIT:\n",
        "            # Neu qua it anh, cho tat ca vao train\n",
        "            dst_dir = os.path.join(TEMP_SPLIT, \"train\", pid)\n",
        "            os.makedirs(dst_dir, exist_ok=True)\n",
        "            for img in images:\n",
        "                shutil.copy(os.path.join(src_dir, img), os.path.join(dst_dir, img))\n",
        "            stats['train'] += len(images)\n",
        "            identity_stats['train'].add(pid)\n",
        "            continue\n",
        "        \n",
        "        random.shuffle(images)\n",
        "        n = len(images)\n",
        "        \n",
        "        # Chia: 80% train, 10% val, 10% test (toi thieu 1 anh moi tap)\n",
        "        n_val = max(1, int(0.1 * n))\n",
        "        n_test = max(1, int(0.1 * n))\n",
        "        n_train = n - n_val - n_test\n",
        "        \n",
        "        # Dam bao train co it nhat 1 anh\n",
        "        if n_train < 1:\n",
        "            n_train = 1\n",
        "            remaining = n - n_train\n",
        "            n_val = remaining // 2\n",
        "            n_test = remaining - n_val\n",
        "        \n",
        "        splits_imgs = {\n",
        "            'train': images[:n_train],\n",
        "            'val': images[n_train:n_train + n_val],\n",
        "            'test': images[n_train + n_val:]\n",
        "        }\n",
        "        \n",
        "        for split, split_imgs in splits_imgs.items():\n",
        "            if len(split_imgs) == 0:\n",
        "                continue\n",
        "            dst_dir = os.path.join(TEMP_SPLIT, split, pid)\n",
        "            os.makedirs(dst_dir, exist_ok=True)\n",
        "            for img in split_imgs:\n",
        "                shutil.copy(os.path.join(src_dir, img), os.path.join(dst_dir, img))\n",
        "            stats[split] += len(split_imgs)\n",
        "            identity_stats[split].add(pid)\n",
        "\n",
        "else:\n",
        "    # Chia theo IDENTITY - moi identity chi o 1 tap\n",
        "    random.shuffle(all_ids)\n",
        "    n_total = len(all_ids)\n",
        "    n_val = int(VAL_RATIO * n_total)\n",
        "    n_test = int(TEST_RATIO * n_total)\n",
        "    \n",
        "    split_ids = {\n",
        "        'train': all_ids[:n_total - n_val - n_test],\n",
        "        'val': all_ids[n_total - n_val - n_test:n_total - n_test],\n",
        "        'test': all_ids[n_total - n_test:]\n",
        "    }\n",
        "    \n",
        "    for split, ids_list in split_ids.items():\n",
        "        for pid in tqdm(ids_list, desc=f\"Copying {split}\"):\n",
        "            src_dir = os.path.join(TEMP_BY_ID, pid)\n",
        "            dst_dir = os.path.join(TEMP_SPLIT, split, pid)\n",
        "            if os.path.exists(src_dir):\n",
        "                shutil.copytree(src_dir, dst_dir)\n",
        "                stats[split] += len([f for f in os.listdir(dst_dir) if f.endswith('.jpg')])\n",
        "                identity_stats[split].add(pid)\n",
        "\n",
        "# In ket qua\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"KET QUA CHIA DATASET ({SPLIT_METHOD})\")\n",
        "print(f\"{'='*50}\")\n",
        "total = sum(stats.values())\n",
        "for split in ['train', 'val', 'test']:\n",
        "    n_imgs = stats[split]\n",
        "    n_ids = len(identity_stats[split])\n",
        "    print(f\"  {split:5}: {n_imgs:,} anh ({100*n_imgs/total:.1f}%), {n_ids} identities\")\n",
        "\n",
        "# Kiem tra overlap\n",
        "if SPLIT_METHOD == 'by_image':\n",
        "    all_have_3_splits = identity_stats['train'] & identity_stats['val'] & identity_stats['test']\n",
        "    print(f\"\\nIdentity co anh trong CA 3 tap: {len(all_have_3_splits)}\")\n",
        "else:\n",
        "    overlap_tv = identity_stats['train'] & identity_stats['val']\n",
        "    overlap_tt = identity_stats['train'] & identity_stats['test']\n",
        "    print(f\"\\nTrain & Val overlap: {len(overlap_tv)}\")\n",
        "    print(f\"Train & Test overlap: {len(overlap_tt)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Buoc 5: Alignment theo chuan ArcFace (112x112)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load landmarks\n",
        "df_landmark = pd.read_csv(LANDMARK_FILE)\n",
        "landmarks = {}\n",
        "for _, row in df_landmark.iterrows():\n",
        "    img = row['image_id']\n",
        "    landmarks[img] = {\n",
        "        \"left_eye\": (row['lefteye_x'], row['lefteye_y']),\n",
        "        \"right_eye\": (row['righteye_x'], row['righteye_y']),\n",
        "        \"nose\": (row['nose_x'], row['nose_y']),\n",
        "        \"left_mouth\": (row['leftmouth_x'], row['leftmouth_y']),\n",
        "        \"right_mouth\": (row['rightmouth_x'], row['rightmouth_y']),\n",
        "    }\n",
        "print(f\"Loaded {len(landmarks)} landmarks\")\n",
        "\n",
        "def align_face(img, landmark):\n",
        "    src = np.array([\n",
        "        landmark[\"left_eye\"], landmark[\"right_eye\"], landmark[\"nose\"],\n",
        "        landmark[\"left_mouth\"], landmark[\"right_mouth\"]\n",
        "    ], dtype=np.float32)\n",
        "    \n",
        "    tform = SimilarityTransform()\n",
        "    tform.estimate(src, ARCFACE_TEMPLATE)\n",
        "    M = tform.params[0:2, :]\n",
        "    return cv2.warpAffine(img, M, (112, 112), borderValue=0)\n",
        "\n",
        "def align_face_center_crop(img):\n",
        "    h, w = img.shape[:2]\n",
        "    if h > w:\n",
        "        start = (h - w) // 2\n",
        "        img = img[start:start+w, :]\n",
        "    elif w > h:\n",
        "        start = (w - h) // 2\n",
        "        img = img[:, start:start+h]\n",
        "    return cv2.resize(img, (112, 112), interpolation=cv2.INTER_LINEAR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chay alignment\n",
        "os.makedirs(FINAL_OUTPUT, exist_ok=True)\n",
        "align_stats = {'aligned': 0, 'center_crop': 0, 'failed': 0}\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_dir = os.path.join(TEMP_SPLIT, split)\n",
        "    out_split_dir = os.path.join(FINAL_OUTPUT, split)\n",
        "    os.makedirs(out_split_dir, exist_ok=True)\n",
        "    \n",
        "    persons = os.listdir(split_dir)\n",
        "    \n",
        "    for person in tqdm(persons, desc=f\"Aligning {split}\"):\n",
        "        src_person_dir = os.path.join(split_dir, person)\n",
        "        dst_person_dir = os.path.join(out_split_dir, person)\n",
        "        os.makedirs(dst_person_dir, exist_ok=True)\n",
        "        \n",
        "        for img_name in os.listdir(src_person_dir):\n",
        "            if not img_name.endswith('.jpg'):\n",
        "                continue\n",
        "            \n",
        "            img_path = os.path.join(src_person_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                align_stats['failed'] += 1\n",
        "                continue\n",
        "            \n",
        "            original_name = img_name.split('_aug')[0] + '.jpg' if '_aug' in img_name else img_name\n",
        "            \n",
        "            if original_name in landmarks:\n",
        "                aligned = align_face(img, landmarks[original_name])\n",
        "                align_stats['aligned'] += 1\n",
        "            else:\n",
        "                aligned = align_face_center_crop(img)\n",
        "                align_stats['center_crop'] += 1\n",
        "            \n",
        "            cv2.imwrite(os.path.join(dst_person_dir, img_name), aligned)\n",
        "\n",
        "print(f\"\\nAlignment stats:\")\n",
        "print(f\"  Aligned with landmarks: {align_stats['aligned']:,}\")\n",
        "print(f\"  Center crop (augmented): {align_stats['center_crop']:,}\")\n",
        "print(f\"  Failed: {align_stats['failed']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Buoc 6: Tao Metadata cho training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tao metadata\n",
        "META_OUTPUT = os.path.join(FINAL_OUTPUT, \"metadata\")\n",
        "os.makedirs(META_OUTPUT, exist_ok=True)\n",
        "\n",
        "# Tao GLOBAL label mapping tu train set\n",
        "train_dir = os.path.join(FINAL_OUTPUT, \"train\")\n",
        "all_train_ids = sorted(os.listdir(train_dir))\n",
        "global_id_to_label = {pid: idx for idx, pid in enumerate(all_train_ids)}\n",
        "print(f\"Total training identities: {len(global_id_to_label)}\")\n",
        "\n",
        "# Luu global mapping\n",
        "global_mapping_df = pd.DataFrame([\n",
        "    {\"identity_id\": pid, \"label\": label} for pid, label in global_id_to_label.items()\n",
        "])\n",
        "global_mapping_df.to_csv(os.path.join(META_OUTPUT, \"global_id_mapping.csv\"), index=False)\n",
        "\n",
        "# Tao labels file cho moi split\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_dir = os.path.join(FINAL_OUTPUT, split)\n",
        "    records = []\n",
        "    \n",
        "    for pid in os.listdir(split_dir):\n",
        "        person_dir = os.path.join(split_dir, pid)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        \n",
        "        label = global_id_to_label.get(pid, -1)\n",
        "        \n",
        "        for img_name in os.listdir(person_dir):\n",
        "            if img_name.endswith('.jpg'):\n",
        "                records.append({\n",
        "                    \"image\": f\"{pid}/{img_name}\",\n",
        "                    \"identity_id\": pid,\n",
        "                    \"label\": label,\n",
        "                    \"is_augmented\": 1 if '_aug' in img_name else 0\n",
        "                })\n",
        "    \n",
        "    df = pd.DataFrame(records)\n",
        "    df.to_csv(os.path.join(META_OUTPUT, f\"{split}_labels.csv\"), index=False)\n",
        "    \n",
        "    n_ids = df['identity_id'].nunique()\n",
        "    n_imgs = len(df)\n",
        "    n_aug = df['is_augmented'].sum()\n",
        "    print(f\"{split}: {n_imgs:,} images, {n_ids} identities, {n_aug:,} augmented\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tao dataset config\n",
        "dataset_config = {\n",
        "    \"dataset_name\": \"CelebA_Aligned_Balanced\",\n",
        "    \"preprocessing\": {\n",
        "        \"min_images_per_identity\": MIN_IMAGES,\n",
        "        \"augment_threshold\": AUGMENT_THRESHOLD,\n",
        "        \"target_min_images\": TARGET_MIN_IMAGES\n",
        "    },\n",
        "    \"image_size\": [112, 112],\n",
        "    \"arcface_landmarks\": {\n",
        "        \"left_eye\": [38.2946, 51.6963],\n",
        "        \"right_eye\": [73.5318, 51.5014],\n",
        "        \"nose\": [56.0252, 71.7366],\n",
        "        \"left_mouth\": [41.5493, 92.3655],\n",
        "        \"right_mouth\": [70.7299, 92.2041]\n",
        "    },\n",
        "    \"split_method\": SPLIT_METHOD,  # 'by_image' hoac 'by_identity'\n",
        "    \"split_ratio\": {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1},\n",
        "    \"splits\": {}\n",
        "}\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    labels_df = pd.read_csv(os.path.join(META_OUTPUT, f\"{split}_labels.csv\"))\n",
        "    dataset_config[\"splits\"][split] = {\n",
        "        \"num_identities\": int(labels_df['identity_id'].nunique()),\n",
        "        \"num_images\": int(len(labels_df)),\n",
        "        \"num_augmented\": int(labels_df['is_augmented'].sum())\n",
        "    }\n",
        "\n",
        "with open(os.path.join(META_OUTPUT, \"dataset_config.json\"), \"w\") as f:\n",
        "    json.dump(dataset_config, f, indent=2)\n",
        "\n",
        "print(json.dumps(dataset_config, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kiem tra va hoan thanh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kiem tra phan bo identity giua cac split\n",
        "train_ids_final = set(os.listdir(os.path.join(FINAL_OUTPUT, \"train\")))\n",
        "val_ids_final = set(os.listdir(os.path.join(FINAL_OUTPUT, \"val\")))\n",
        "test_ids_final = set(os.listdir(os.path.join(FINAL_OUTPUT, \"test\")))\n",
        "\n",
        "print(f\"Phuong phap chia: {SPLIT_METHOD}\")\n",
        "print(f\"\\nSo identity moi split:\")\n",
        "print(f\"  Train: {len(train_ids_final)}\")\n",
        "print(f\"  Val: {len(val_ids_final)}\")\n",
        "print(f\"  Test: {len(test_ids_final)}\")\n",
        "\n",
        "# Kiem tra overlap\n",
        "overlap_tv = train_ids_final & val_ids_final\n",
        "overlap_tt = train_ids_final & test_ids_final\n",
        "overlap_vt = val_ids_final & test_ids_final\n",
        "overlap_all = train_ids_final & val_ids_final & test_ids_final\n",
        "\n",
        "print(f\"\\nIdentity overlap giua cac split:\")\n",
        "print(f\"  Train & Val: {len(overlap_tv)}\")\n",
        "print(f\"  Train & Test: {len(overlap_tt)}\")\n",
        "print(f\"  Val & Test: {len(overlap_vt)}\")\n",
        "print(f\"  CA 3 tap: {len(overlap_all)}\")\n",
        "\n",
        "if SPLIT_METHOD == 'by_image':\n",
        "    if len(overlap_all) > 0:\n",
        "        print(f\"\\n[OK] Co {len(overlap_all)} identity xuat hien trong CA 3 tap - Dung cho Face Verification!\")\n",
        "    else:\n",
        "        print(\"\\n[WARNING] Khong co identity nao xuat hien trong ca 3 tap!\")\n",
        "else:\n",
        "    if len(overlap_tv) == 0 and len(overlap_tt) == 0:\n",
        "        print(\"\\n[OK] KHONG CO CHONG CHEO - Dung cho Face Identification!\")\n",
        "    else:\n",
        "        print(\"\\n[ERROR] CO CHONG CHEO - Can kiem tra lai!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tao file ZIP va luu vao Drive\n",
        "print(\"Tao file ZIP tu thu muc local...\")\n",
        "zip_filename = \"CelebA_Aligned_Balanced.zip\"\n",
        "\n",
        "if MODE == 'colab':\n",
        "    # Tren Colab: Tao ZIP tren local roi copy len Drive\n",
        "    local_zip = f\"/content/{zip_filename}\"\n",
        "    drive_zip = f\"{DRIVE_OUTPUT}/{zip_filename}\"\n",
        "    \n",
        "    # Tao ZIP tu FINAL_OUTPUT (local Colab)\n",
        "    !cd /content && zip -r \"{local_zip}\" \"CelebA_Aligned_Balanced/\" -x \"*.DS_Store\"\n",
        "    \n",
        "    # Copy ZIP len Drive\n",
        "    print(f\"Upload ZIP len Drive: {drive_zip}\")\n",
        "    shutil.copy(local_zip, drive_zip)\n",
        "    \n",
        "    print(f\"\\n[OK] File ZIP da luu: {drive_zip}\")\n",
        "    !ls -lh \"{drive_zip}\"\n",
        "    \n",
        "    # Xoa cac thu muc tam va ZIP local\n",
        "    print(\"\\nXoa cac thu muc tam va file ZIP local...\")\n",
        "    !rm -rf \"{TEMP_BY_ID}\"\n",
        "    !rm -rf \"{TEMP_SPLIT}\"\n",
        "    !rm -rf \"{FINAL_OUTPUT}\"\n",
        "    !rm -f \"{local_zip}\"\n",
        "    \n",
        "    final_location = drive_zip\n",
        "else:\n",
        "    # Tren Local: Chi tao ZIP\n",
        "    local_zip = f\"{os.path.dirname(FINAL_OUTPUT)}/{zip_filename}\"\n",
        "    !cd \"{os.path.dirname(FINAL_OUTPUT)}\" && zip -r \"{zip_filename}\" \"{os.path.basename(FINAL_OUTPUT)}/\" -x \"*.DS_Store\"\n",
        "    \n",
        "    print(f\"\\n[OK] File ZIP da tao: {local_zip}\")\n",
        "    final_location = local_zip\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HOAN THANH XU LY DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nFile ZIP: {final_location}\")\n",
        "print(f\"Kich thuoc: \", end=\"\")\n",
        "!du -h \"{final_location}\"\n",
        "print(\"\\nChi co file ZIP duoc luu, cac thu muc tam da bi xoa.\")\n",
        "print(\"\\nCac buoc tiep theo:\")\n",
        "print(\"1. Download file ZIP ve local (neu dang tren Colab)\")\n",
        "print(\"2. Giai nen va su dung FolderBasedDataset/ArcFaceDataset de load du lieu\")\n",
        "print(\"3. Training voi class_balanced_sampling=True\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
