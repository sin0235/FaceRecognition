{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract Embeddings - Kaggle\n",
        "\n",
        "Notebook tao embeddings database tren Kaggle voi GPU mien phi.\n",
        "\n",
        "## Chuan bi:\n",
        "1. Upload dataset `CelebA_Aligned_Balanced` len Kaggle Datasets\n",
        "2. Upload folder `data/celeb` (chua anh celebrities) len Kaggle Datasets\n",
        "3. Upload checkpoint model (arcface_best.pth/facenet_best.pth) len Kaggle Datasets\n",
        "4. Add tat ca datasets vao notebook nay\n",
        "5. Bat GPU: Settings > Accelerator > GPU P100/T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "print(f\"Kaggle environment: {IS_KAGGLE}\")\n",
        "\n",
        "if not IS_KAGGLE:\n",
        "    print(\"WARNING: Notebook nay duoc thiet ke cho Kaggle!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
        "!pip install protobuf==3.20.* --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# === CAU HINH DUONG DAN ===\n",
        "# Thay doi cac ten dataset theo ten ban da upload len Kaggle\n",
        "\n",
        "ROOT = \"/kaggle/working/FaceRecognition\"\n",
        "OUTPUT_DIR = \"/kaggle/working/embeddings\"\n",
        "\n",
        "# Dataset chua anh celebrities de tao embeddings\n",
        "CELEB_DATASET_NAME = \"celeb-dataset\"  # Thay doi neu can\n",
        "CELEB_DATA_DIR = f\"/kaggle/input/{CELEB_DATASET_NAME}\"\n",
        "\n",
        "# Dataset chua checkpoint model\n",
        "CHECKPOINT_DATASET_NAME = \"arcface-checkpoints\"  # Thay doi neu can\n",
        "CHECKPOINT_DIR = f\"/kaggle/input/{CHECKPOINT_DATASET_NAME}\"\n",
        "\n",
        "# Chon model type: 'arcface' hoac 'facenet'\n",
        "MODEL_TYPE = \"arcface\"  # Thay doi neu can\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"ROOT: {ROOT}\")\n",
        "print(f\"CELEB_DATA_DIR: {CELEB_DATA_DIR}\")\n",
        "print(f\"CHECKPOINT_DIR: {CHECKPOINT_DIR}\")\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
        "print(f\"MODEL_TYPE: {MODEL_TYPE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"=== KIEM TRA DATASETS ===\\n\")\n",
        "\n",
        "print(\"Tat ca datasets:\")\n",
        "!ls -la /kaggle/input/\n",
        "\n",
        "print(f\"\\n--- Celeb Dataset ({CELEB_DATA_DIR}) ---\")\n",
        "if os.path.exists(CELEB_DATA_DIR):\n",
        "    !ls -la {CELEB_DATA_DIR} | head -20\n",
        "    num_persons = len([d for d in os.listdir(CELEB_DATA_DIR) if os.path.isdir(os.path.join(CELEB_DATA_DIR, d))])\n",
        "    print(f\"\\n[OK] Tim thay {num_persons} thu muc celebrity\")\n",
        "else:\n",
        "    print(f\"[ERROR] Khong tim thay: {CELEB_DATA_DIR}\")\n",
        "    print(\"        Hay add dataset celeb vao notebook\")\n",
        "\n",
        "print(f\"\\n--- Checkpoint Dataset ({CHECKPOINT_DIR}) ---\")\n",
        "if os.path.exists(CHECKPOINT_DIR):\n",
        "    !ls -la {CHECKPOINT_DIR}\n",
        "else:\n",
        "    print(f\"[ERROR] Khong tim thay: {CHECKPOINT_DIR}\")\n",
        "    print(\"        Hay add dataset checkpoint vao notebook\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
        "    print(\"[OK] Da lay GITHUB_TOKEN tu Kaggle Secrets\")\n",
        "except Exception as e:\n",
        "    GITHUB_TOKEN = None\n",
        "    print(\"[WARN] Khong lay duoc token tu Kaggle Secrets\")\n",
        "    print(f\"       Loi: {e}\")\n",
        "\n",
        "if GITHUB_TOKEN:\n",
        "    REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/sin0235/FaceRecognition.git\"\n",
        "    print(\"[OK] GitHub token da duoc cau hinh\")\n",
        "else:\n",
        "    REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\"\n",
        "    print(\"[INFO] Su dung public URL (khong can token)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "if os.path.exists(ROOT):\n",
        "    print(\"Repository da ton tai, dang pull updates...\")\n",
        "    %cd {ROOT}\n",
        "    if GITHUB_TOKEN:\n",
        "        !git remote set-url origin {REPO_URL}\n",
        "    !git pull\n",
        "else:\n",
        "    print(f\"Dang clone repository...\")\n",
        "    !git clone {REPO_URL} {ROOT}\n",
        "    %cd {ROOT}\n",
        "\n",
        "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "if ROOT not in sys.path:\n",
        "    sys.path.insert(0, ROOT)\n",
        "    print(f\"Da them {ROOT} vao Python path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"Cai dat dependencies...\")\n",
        "!pip install -q opencv-python-headless Pillow scikit-learn tqdm pyyaml facenet-pytorch\n",
        "!pip install -q scikit-image\n",
        "print(\"\\nHoan tat cai dat!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import torch\n",
        "\n",
        "print(\"=== GPU INFO ===\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nSu dung device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import glob\n",
        "\n",
        "print(\"=== TIM CHECKPOINT ===\\n\")\n",
        "\n",
        "pth_files = glob.glob(os.path.join(CHECKPOINT_DIR, \"**/*.pth\"), recursive=True)\n",
        "\n",
        "if pth_files:\n",
        "    print(f\"Tim thay {len(pth_files)} file checkpoint:\")\n",
        "    for f in pth_files:\n",
        "        print(f\"  - {f}\")\n",
        "    \n",
        "    if MODEL_TYPE == \"arcface\":\n",
        "        model_file = next((f for f in pth_files if 'arcface' in f.lower() and 'best' in f.lower()), None)\n",
        "        if not model_file:\n",
        "            model_file = next((f for f in pth_files if 'arcface' in f.lower()), None)\n",
        "    else:\n",
        "        model_file = next((f for f in pth_files if 'facenet' in f.lower() and 'best' in f.lower()), None)\n",
        "        if not model_file:\n",
        "            model_file = next((f for f in pth_files if 'facenet' in f.lower()), None)\n",
        "    \n",
        "    if not model_file:\n",
        "        model_file = pth_files[0]\n",
        "    \n",
        "    MODEL_PATH = model_file\n",
        "    print(f\"\\n[OK] Se su dung: {MODEL_PATH}\")\n",
        "else:\n",
        "    print(f\"[ERROR] Khong tim thay file .pth trong {CHECKPOINT_DIR}\")\n",
        "    MODEL_PATH = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    from skimage.transform import SimilarityTransform\n",
        "    HAS_SKIMAGE = True\n",
        "    print(\"[OK] scikit-image available\")\n",
        "except ImportError:\n",
        "    HAS_SKIMAGE = False\n",
        "    print(\"[WARN] scikit-image not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "ARCFACE_TEMPLATE = np.array([\n",
        "    [38.2946, 51.6963],\n",
        "    [73.5318, 51.5014],\n",
        "    [56.0252, 71.7366],\n",
        "    [41.5493, 92.3655],\n",
        "    [70.7299, 92.2041]\n",
        "], dtype=np.float32)\n",
        "\n",
        "\n",
        "def get_transform(image_size: int = 112):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "\n",
        "def get_facenet_transform(image_size: int = 160):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def load_arcface_model(model_path: str, device: str = 'cpu'):\n",
        "    from models.arcface.arcface_model import ArcFaceModel\n",
        "    \n",
        "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    \n",
        "    config = checkpoint.get('config', {})\n",
        "    num_classes = config.get('num_classes', checkpoint.get('num_classes', 100))\n",
        "    embedding_size = config.get('model', {}).get('embedding_size', 512)\n",
        "    \n",
        "    model = ArcFaceModel(num_classes=num_classes, embedding_size=embedding_size)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Loaded ArcFace model:\")\n",
        "    print(f\"  - Num classes: {num_classes}\")\n",
        "    print(f\"  - Embedding size: {embedding_size}\")\n",
        "    print(f\"  - Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
        "    \n",
        "    return model, embedding_size\n",
        "\n",
        "\n",
        "def load_facenet_model(model_path: str, device: str = 'cpu'):\n",
        "    from models.facenet.facenet_model import FaceNetModel\n",
        "    \n",
        "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    \n",
        "    config = checkpoint.get('config', {})\n",
        "    embedding_size = config.get('model', {}).get('embedding_size', 512)\n",
        "    \n",
        "    model = FaceNetModel(embedding_size=embedding_size, pretrained='vggface2', device=device)\n",
        "    \n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "    elif 'state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Loaded FaceNet model:\")\n",
        "    print(f\"  - Embedding size: {embedding_size}\")\n",
        "    print(f\"  - Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
        "    \n",
        "    return model, embedding_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def extract_embedding_single(img_input, model, transform, device, model_type='arcface'):\n",
        "    try:\n",
        "        if isinstance(img_input, str):\n",
        "            img = Image.open(img_input).convert('RGB')\n",
        "        else:\n",
        "            img = img_input.convert('RGB')\n",
        "            \n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            if model_type == 'facenet':\n",
        "                embedding = model(img_tensor)\n",
        "            else:\n",
        "                embedding = model(img_tensor, labels=None)\n",
        "            embedding = F.normalize(embedding, p=2, dim=1)\n",
        "            embedding = embedding.cpu().numpy().flatten()\n",
        "        \n",
        "        return embedding\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_embedding_for_folder(folder, model, transform, device, model_type='arcface'):\n",
        "    if not os.path.exists(folder):\n",
        "        return None\n",
        "    \n",
        "    embeddings = []\n",
        "    \n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')):\n",
        "            img_path = os.path.join(folder, f)\n",
        "            emb = extract_embedding_single(img_path, model, transform, device, model_type)\n",
        "            if emb is not None:\n",
        "                embeddings.append(emb)\n",
        "    \n",
        "    if len(embeddings) == 0:\n",
        "        return None\n",
        "    \n",
        "    stacked = np.stack(embeddings, axis=0)\n",
        "    mean_emb = np.mean(stacked, axis=0)\n",
        "    mean_emb = mean_emb / (np.linalg.norm(mean_emb) + 1e-8)\n",
        "    \n",
        "    return mean_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "if MODEL_PATH is None:\n",
        "    print(\"[ERROR] Khong co model checkpoint!\")\n",
        "else:\n",
        "    print(\"=\"*60)\n",
        "    print(f\"LOADING MODEL: {MODEL_TYPE.upper()}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if MODEL_TYPE == \"facenet\":\n",
        "        model, embedding_size = load_facenet_model(MODEL_PATH, DEVICE)\n",
        "        transform = get_facenet_transform()\n",
        "    else:\n",
        "        model, embedding_size = load_arcface_model(MODEL_PATH, DEVICE)\n",
        "        transform = get_transform()\n",
        "    \n",
        "    print(f\"\\n[OK] Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"=\"*60)\n",
        "print(\"EXTRACT EMBEDDINGS DATABASE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "actual_celeb_dir = CELEB_DATA_DIR\n",
        "if not os.path.exists(actual_celeb_dir):\n",
        "    for subdir in os.listdir(CELEB_DATA_DIR):\n",
        "        subpath = os.path.join(CELEB_DATA_DIR, subdir)\n",
        "        if os.path.isdir(subpath):\n",
        "            num_subdirs = len([d for d in os.listdir(subpath) if os.path.isdir(os.path.join(subpath, d))])\n",
        "            if num_subdirs > 0:\n",
        "                actual_celeb_dir = subpath\n",
        "                break\n",
        "\n",
        "print(f\"Data directory: {actual_celeb_dir}\")\n",
        "\n",
        "persons = [p for p in os.listdir(actual_celeb_dir)\n",
        "           if os.path.isdir(os.path.join(actual_celeb_dir, p))]\n",
        "\n",
        "print(f\"Tim thay {len(persons)} celebrities\")\n",
        "print(f\"Model type: {MODEL_TYPE}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(\"\\nDang extract embeddings...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "db = {}\n",
        "success_count = 0\n",
        "failed_persons = []\n",
        "\n",
        "for person in tqdm(persons, desc=\"Extracting embeddings\"):\n",
        "    person_folder = os.path.join(actual_celeb_dir, person)\n",
        "    emb = extract_embedding_for_folder(person_folder, model, transform, DEVICE, MODEL_TYPE)\n",
        "    if emb is not None:\n",
        "        db[person] = emb\n",
        "        success_count += 1\n",
        "    else:\n",
        "        failed_persons.append(person)\n",
        "\n",
        "print(f\"\\n=== KET QUA ===\")\n",
        "print(f\"Thanh cong: {success_count}/{len(persons)}\")\n",
        "print(f\"That bai: {len(failed_persons)}\")\n",
        "\n",
        "if failed_persons:\n",
        "    print(f\"\\nCac thu muc that bai:\")\n",
        "    for p in failed_persons[:10]:\n",
        "        print(f\"  - {p}\")\n",
        "    if len(failed_persons) > 10:\n",
        "        print(f\"  ... va {len(failed_persons) - 10} thu muc khac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "if len(db) > 0:\n",
        "    output_filename = f\"{MODEL_TYPE}_embeddings_db.npy\"\n",
        "    output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
        "    \n",
        "    np.save(output_path, db)\n",
        "    \n",
        "    print(f\"\\n[OK] Da luu embeddings database!\")\n",
        "    print(f\"     File: {output_path}\")\n",
        "    print(f\"     So celebrities: {len(db)}\")\n",
        "    print(f\"     Embedding size: {embedding_size}\")\n",
        "    \n",
        "    file_size = os.path.getsize(output_path) / 1024 / 1024\n",
        "    print(f\"     File size: {file_size:.2f} MB\")\n",
        "else:\n",
        "    print(\"[ERROR] Khong co embeddings nao duoc tao!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"=== KIEM TRA DATABASE ===\\n\")\n",
        "\n",
        "if len(db) > 0:\n",
        "    sample_names = list(db.keys())[:5]\n",
        "    print(f\"Sample celebrities:\")\n",
        "    for name in sample_names:\n",
        "        emb = db[name]\n",
        "        print(f\"  - {name}: shape={emb.shape}, norm={np.linalg.norm(emb):.4f}\")\n",
        "    \n",
        "    print(f\"\\nTinh similarity giua 2 nguoi dau tien:\")\n",
        "    if len(sample_names) >= 2:\n",
        "        emb1 = db[sample_names[0]]\n",
        "        emb2 = db[sample_names[1]]\n",
        "        similarity = np.dot(emb1, emb2)\n",
        "        print(f\"  {sample_names[0]} vs {sample_names[1]}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "print(\"=== OUTPUT FILES ===\\n\")\n",
        "!ls -la {OUTPUT_DIR}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HOAN TAT!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nDownload file embeddings tu: {OUTPUT_DIR}\")\n",
        "print(\"Copy file nay vao thu muc data/ cua project de su dung.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Huong dan su dung\n",
        "\n",
        "1. **Chuan bi datasets tren Kaggle:**\n",
        "   - Upload folder `data/celeb` (chua anh celebrities) thanh 1 dataset\n",
        "   - Upload file checkpoint (arcface_best.pth hoac facenet_best.pth) thanh 1 dataset\n",
        "\n",
        "2. **Cau hinh notebook:**\n",
        "   - Sua ten dataset trong cell cau hinh (CELEB_DATASET_NAME, CHECKPOINT_DATASET_NAME)\n",
        "   - Chon MODEL_TYPE: 'arcface' hoac 'facenet'\n",
        "\n",
        "3. **Chay notebook:**\n",
        "   - Bat GPU trong Settings\n",
        "   - Run All cells\n",
        "\n",
        "4. **Download output:**\n",
        "   - File embeddings se o trong /kaggle/working/embeddings/\n",
        "   - Download va copy vao thu muc data/ cua project"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
