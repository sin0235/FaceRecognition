{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcFace Training - Kaggle\n",
    "\n",
    "Notebook huấn luyện ArcFace trên Kaggle với GPU miễn phí.\n",
    "\n",
    "## Chuẩn bị:\n",
    "1. Upload dataset `CelebA_Aligned_Balanced` lên Kaggle Datasets\n",
    "2. Add dataset vào notebook này\n",
    "3. Bật GPU: Settings > Accelerator > GPU P100/T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:17.987161Z",
     "iopub.status.busy": "2025-12-12T17:07:17.986349Z",
     "iopub.status.idle": "2025-12-12T17:07:17.992413Z",
     "shell.execute_reply": "2025-12-12T17:07:17.991522Z",
     "shell.execute_reply.started": "2025-12-12T17:07:17.987118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Detect môi trường\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "print(f\"Kaggle environment: {IS_KAGGLE}\")\n",
    "\n",
    "if not IS_KAGGLE:\n",
    "    print(\"WARNING: Notebook này được thiết kế cho Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:17.993836Z",
     "iopub.status.busy": "2025-12-12T17:07:17.993592Z",
     "iopub.status.idle": "2025-12-12T17:07:21.184457Z",
     "shell.execute_reply": "2025-12-12T17:07:21.183691Z",
     "shell.execute_reply.started": "2025-12-12T17:07:17.993819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fix protobuf compatibility issue\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# Hoặc nếu muốn fix triệt để, chạy:\n",
    "!pip install protobuf==3.20.* --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:21.185632Z",
     "iopub.status.busy": "2025-12-12T17:07:21.185400Z",
     "iopub.status.idle": "2025-12-12T17:07:21.191061Z",
     "shell.execute_reply": "2025-12-12T17:07:21.190294Z",
     "shell.execute_reply.started": "2025-12-12T17:07:21.185609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình đường dẫn Kaggle\n",
    "# ROOT: thư mục chứa source code (clone từ GitHub)\n",
    "# DATA_DIR: thư mục chứa dataset (từ Kaggle Datasets)\n",
    "# CHECKPOINT_DIR: thư mục lưu model checkpoint\n",
    "\n",
    "ROOT = \"/kaggle/working/FaceRecognition\"\n",
    "CHECKPOINT_DIR = \"/kaggle/working/checkpoints/arcface\"\n",
    "\n",
    "# Dataset path - thay đổi theo tên dataset của bạn trên Kaggle\n",
    "# Sau khi add dataset, kiểm tra đường dẫn: !ls /kaggle/input/\n",
    "KAGGLE_DATASET_NAME = \"celeba-aligned-balanced\"  # Thay đổi nếu cần\n",
    "DATA_DIR = f\"/kaggle/input/{KAGGLE_DATASET_NAME}\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ROOT: {ROOT}\")\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"CHECKPOINT_DIR: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:21.193121Z",
     "iopub.status.busy": "2025-12-12T17:07:21.192801Z",
     "iopub.status.idle": "2025-12-12T17:07:21.206693Z",
     "shell.execute_reply": "2025-12-12T17:07:21.205976Z",
     "shell.execute_reply.started": "2025-12-12T17:07:21.193103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === CAU HINH CHECKPOINT DATASET ===\n",
    "# Neu ban da upload checkpoint (.pth) len Kaggle Dataset de resume training,\n",
    "# hay dien ten dataset vao day.\n",
    "# Vi du: neu ban tao dataset ten 'arcface-checkpoints' chua file arcface_last.pth\n",
    "#        thi dat CHECKPOINT_DATASET_NAME = 'arcface-checkpoints'\n",
    "\n",
    "CHECKPOINT_DATASET_NAME = \"arcface-checkpoints\"  # Thay doi neu co dataset checkpoint\n",
    "# Vi du: CHECKPOINT_DATASET_NAME = \"arcface-checkpoints\"\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "if CHECKPOINT_DATASET_NAME:\n",
    "    checkpoint_input_dir = f\"/kaggle/input/{CHECKPOINT_DATASET_NAME}\"\n",
    "    \n",
    "    if os.path.exists(checkpoint_input_dir):\n",
    "        print(f\"[OK] Tim thay checkpoint dataset: {checkpoint_input_dir}\")\n",
    "        \n",
    "        # Tim tat ca file .pth trong dataset\n",
    "        pth_files = glob.glob(os.path.join(checkpoint_input_dir, \"**/*.pth\"), recursive=True)\n",
    "        \n",
    "        if pth_files:\n",
    "            print(f\"    Tim thay {len(pth_files)} file checkpoint:\")\n",
    "            for pth_file in pth_files:\n",
    "                print(f\"      - {os.path.basename(pth_file)}\")\n",
    "            \n",
    "            # Copy cac file .pth sang CHECKPOINT_DIR de resume\n",
    "            os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "            for pth_file in pth_files:\n",
    "                dest_path = os.path.join(CHECKPOINT_DIR, os.path.basename(pth_file))\n",
    "                if not os.path.exists(dest_path):\n",
    "                    shutil.copy(pth_file, dest_path)\n",
    "                    print(f\"[COPY] {os.path.basename(pth_file)} -> {CHECKPOINT_DIR}\")\n",
    "                else:\n",
    "                    print(f\"[SKIP] {os.path.basename(pth_file)} - da ton tai\")\n",
    "            \n",
    "            # Hien thi thong tin checkpoint\n",
    "            last_ckpt = os.path.join(CHECKPOINT_DIR, \"arcface_last.pth\")\n",
    "            if os.path.exists(last_ckpt):\n",
    "                import torch\n",
    "                ckpt = torch.load(last_ckpt, map_location='cpu', weights_only=False)\n",
    "                print(f\"\\n[INFO] Checkpoint info:\")\n",
    "                print(f\"       Epoch: {ckpt.get('epoch', 0) + 1}\")\n",
    "                print(f\"       Best val acc: {ckpt.get('best_val_acc', 0):.2f}%\")\n",
    "        else:\n",
    "            print(f\"[WARN] Khong tim thay file .pth trong {checkpoint_input_dir}\")\n",
    "    else:\n",
    "        print(f\"[ERROR] Khong tim thay checkpoint dataset: {checkpoint_input_dir}\")\n",
    "        print(\"        Kiem tra lai ten dataset hoac add dataset vao notebook\")\n",
    "else:\n",
    "    print(\"[INFO] Khong co CHECKPOINT_DATASET_NAME - Training tu dau\")\n",
    "    print(\"       Neu muon resume, hay:\")\n",
    "    print(\"       1. Upload file .pth len Kaggle Dataset\")\n",
    "    print(\"       2. Add dataset vao notebook\")\n",
    "    print(\"       3. Dat CHECKPOINT_DATASET_NAME = 'ten-dataset-cua-ban'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:21.207607Z",
     "iopub.status.busy": "2025-12-12T17:07:21.207427Z",
     "iopub.status.idle": "2025-12-12T17:07:21.456711Z",
     "shell.execute_reply": "2025-12-12T17:07:21.455897Z",
     "shell.execute_reply.started": "2025-12-12T17:07:21.207591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiểm tra Kaggle dataset đã được add chưa\n",
    "print(\"=== KAGGLE INPUT DATASETS ===\")\n",
    "!ls -la /kaggle/input/\n",
    "\n",
    "if os.path.exists(DATA_DIR):\n",
    "    print(f\"\\n[OK] Dataset found at: {DATA_DIR}\")\n",
    "    !ls -la {DATA_DIR}\n",
    "else:\n",
    "    print(f\"\\n[ERROR] Dataset not found at: {DATA_DIR}\")\n",
    "    print(\"Hãy add dataset vào notebook:\")\n",
    "    print(\"  1. Click 'Add data' ở sidebar bên phải\")\n",
    "    print(\"  2. Tìm và add dataset của bạn\")\n",
    "    print(\"  3. Cập nhật KAGGLE_DATASET_NAME ở cell trên\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:21.458038Z",
     "iopub.status.busy": "2025-12-12T17:07:21.457797Z",
     "iopub.status.idle": "2025-12-12T17:07:21.464712Z",
     "shell.execute_reply": "2025-12-12T17:07:21.464101Z",
     "shell.execute_reply.started": "2025-12-12T17:07:21.458004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cau hinh GitHub token (neu repository la private hoac can authentication)\n",
    "# \n",
    "# HUONG DAN TAO TOKEN:\n",
    "# 1. Vao: https://github.com/settings/tokens\n",
    "# 2. Click \"Generate new token\" > \"Generate new token (classic)\"\n",
    "# 3. Dat ten token (vd: \"Kaggle Training\")\n",
    "# 4. Chon quyen: \n",
    "#    - Neu repo PRIVATE: chon \"repo\" (full control)\n",
    "#    - Neu repo PUBLIC: chon \"public_repo\" (chi can read)\n",
    "# 5. Click \"Generate token\"\n",
    "# 6. COPY token ngay (chi hien 1 lan!)\n",
    "# 7. Dan token vao bien GITHUB_TOKEN ben duoi\n",
    "\n",
    "GITHUB_TOKEN = \"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\"  # DAN TOKEN CUA BAN VAO DAY\n",
    "# Vi du: GITHUB_TOKEN = \"ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "# Hoac su dung Kaggle Secrets (an toan hon):\n",
    "# 1. Vao Settings > Add-ons > Secrets\n",
    "# 2. Them secret: name=\"GITHUB_TOKEN\", value=\"your_token_here\"\n",
    "# 3. Su dung:\n",
    "#    from kaggle_secrets import UserSecretsClient\n",
    "#    user_secrets = UserSecretsClient()\n",
    "#    GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "\n",
    "if GITHUB_TOKEN:\n",
    "    # Cau hinh git de su dung token\n",
    "    REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/sin0235/FaceRecognition.git\"\n",
    "    print(\"[OK] GitHub token da duoc cau hinh\")\n",
    "    print(\"     Repository URL: https://[TOKEN]@github.com/sin0235/FaceRecognition.git\")\n",
    "else:\n",
    "    # Neu khong co token, su dung public URL\n",
    "    REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\"\n",
    "    print(\"[INFO] Su dung public repository (khong can token)\")\n",
    "    print(\"       Neu gap loi authentication, hay them GITHUB_TOKEN o tren\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:21.465751Z",
     "iopub.status.busy": "2025-12-12T17:07:21.465495Z",
     "iopub.status.idle": "2025-12-12T17:07:22.739881Z",
     "shell.execute_reply": "2025-12-12T17:07:22.738953Z",
     "shell.execute_reply.started": "2025-12-12T17:07:21.465733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Clone repository tu GitHub\n",
    "# REPO_URL da duoc dinh nghia o cell truoc (co hoac khong co token)\n",
    "\n",
    "if os.path.exists(ROOT):\n",
    "    print(\"Repository da ton tai, dang pull updates...\")\n",
    "    %cd {ROOT}\n",
    "    # Su dung REPO_URL neu co token\n",
    "    if 'REPO_URL' in dir() and GITHUB_TOKEN:\n",
    "        !git remote set-url origin {REPO_URL}\n",
    "    !git pull\n",
    "else:\n",
    "    print(f\"Dang clone repository...\")\n",
    "    if 'REPO_URL' not in dir():\n",
    "        REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\"\n",
    "        print(\"[WARN] REPO_URL chua duoc dinh nghia, su dung public URL\")\n",
    "    !git clone {REPO_URL} {ROOT}\n",
    "    %cd {ROOT}\n",
    "\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:22.741334Z",
     "iopub.status.busy": "2025-12-12T17:07:22.741037Z",
     "iopub.status.idle": "2025-12-12T17:07:22.746396Z",
     "shell.execute_reply": "2025-12-12T17:07:22.745821Z",
     "shell.execute_reply.started": "2025-12-12T17:07:22.741302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Thêm ROOT vào Python path\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "    print(f\"Đã thêm {ROOT} vào Python path\")\n",
    "\n",
    "print(f\"Python path: {sys.path[:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:22.747465Z",
     "iopub.status.busy": "2025-12-12T17:07:22.747233Z",
     "iopub.status.idle": "2025-12-12T17:07:49.515812Z",
     "shell.execute_reply": "2025-12-12T17:07:49.514791Z",
     "shell.execute_reply.started": "2025-12-12T17:07:22.747445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cai dat dependencies\n",
    "print(\"Cai dat dependencies...\")\n",
    "\n",
    "# Fix NumPy version conflict voi matplotlib\n",
    "!pip install -q \"numpy<2.0\"\n",
    "\n",
    "# PyTorch thuong da co san tren Kaggle, chi cai them packages con thieu\n",
    "!pip install -q opencv-python-headless Pillow scikit-learn tqdm pyyaml\n",
    "\n",
    "# Upgrade matplotlib de tuong thich\n",
    "!pip install -q --upgrade matplotlib\n",
    "\n",
    "print(\"\\nHoan tat cai dat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:49.518794Z",
     "iopub.status.busy": "2025-12-12T17:07:49.518477Z",
     "iopub.status.idle": "2025-12-12T17:07:53.107323Z",
     "shell.execute_reply": "2025-12-12T17:07:53.106516Z",
     "shell.execute_reply.started": "2025-12-12T17:07:49.518770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiểm tra dependencies\n",
    "import torch\n",
    "\n",
    "print(\"=== GPU INFO ===\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"\\n=== DEPENDENCIES ===\")\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    print(f\"onnxruntime: OK ({ort.get_available_providers()})\")\n",
    "except ImportError:\n",
    "    print(\"onnxruntime: NOT INSTALLED\")\n",
    "\n",
    "try:\n",
    "    import insightface\n",
    "    print(f\"insightface: OK (v{insightface.__version__})\")\n",
    "except ImportError:\n",
    "    print(\"insightface: NOT INSTALLED\")\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"opencv: OK\")\n",
    "except ImportError:\n",
    "    print(\"opencv: NOT INSTALLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:53.108714Z",
     "iopub.status.busy": "2025-12-12T17:07:53.108211Z",
     "iopub.status.idle": "2025-12-12T17:07:53.121048Z",
     "shell.execute_reply": "2025-12-12T17:07:53.119692Z",
     "shell.execute_reply.started": "2025-12-12T17:07:53.108687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Copy checkpoint va log tu Kaggle input de resume training\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "CHECKPOINT_DATASET_NAME = \"arcface-checkpoint\"  # Thay doi theo ten dataset cua ban\n",
    "INPUT_CHECKPOINT_DIR = f\"/kaggle/input/{CHECKPOINT_DATASET_NAME}\"\n",
    "\n",
    "print(\"=== KIEM TRA CHECKPOINT VA LOG TU INPUT ===\")\n",
    "\n",
    "files_to_copy = [\n",
    "    (\"arcface_last.pth\", \"Checkpoint cuoi cung\"),\n",
    "    (\"arcface_best.pth\", \"Checkpoint tot nhat\"),\n",
    "    (\"training_history.json\", \"Log training history\")\n",
    "]\n",
    "\n",
    "if os.path.exists(INPUT_CHECKPOINT_DIR):\n",
    "    print(f\"[OK] Tim thay checkpoint dataset: {INPUT_CHECKPOINT_DIR}\")\n",
    "    !ls -la {INPUT_CHECKPOINT_DIR}\n",
    "    \n",
    "    for filename, desc in files_to_copy:\n",
    "        src_path = os.path.join(INPUT_CHECKPOINT_DIR, filename)\n",
    "        dst_path = os.path.join(CHECKPOINT_DIR, filename)\n",
    "        \n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            print(f\"  [COPIED] {desc}: {filename}\")\n",
    "        else:\n",
    "            print(f\"  [SKIP] {desc}: {filename} (khong ton tai)\")\n",
    "    \n",
    "    # Hien thi thong tin checkpoint\n",
    "    last_ckpt = os.path.join(CHECKPOINT_DIR, \"arcface_last.pth\")\n",
    "    if os.path.exists(last_ckpt):\n",
    "        ckpt = torch.load(last_ckpt, map_location='cpu', weights_only=False)\n",
    "        print(f\"\\n[INFO] Checkpoint: Epoch {ckpt['epoch']+1}, Best acc: {ckpt['best_val_acc']:.2f}%\")\n",
    "    \n",
    "    # Hien thi thong tin log\n",
    "    log_path = os.path.join(CHECKPOINT_DIR, \"training_history.json\")\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, 'r') as f:\n",
    "            log_data = json.load(f)\n",
    "        print(f\"[INFO] Log: {log_data.get('total_epochs', 'N/A')} epochs, Best acc: {log_data.get('best_val_acc', 0):.2f}%\")\n",
    "else:\n",
    "    print(f\"[INFO] Khong tim thay: {INPUT_CHECKPOINT_DIR}\")\n",
    "    print(\"Se training tu dau.\")\n",
    "    print(\"\\nDe resume: Upload arcface_last.pth va training_history.json vao Kaggle Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:07:53.122750Z",
     "iopub.status.busy": "2025-12-12T17:07:53.122109Z",
     "iopub.status.idle": "2025-12-12T17:08:18.843088Z",
     "shell.execute_reply": "2025-12-12T17:08:18.842400Z",
     "shell.execute_reply.started": "2025-12-12T17:07:53.122718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiem tra du lieu training (mode: folder - khong can CSV)\n",
    "print(\"=== KIEM TRA DU LIEU ===\")\n",
    "print(\"Mode: folder (khong can file CSV metadata)\\n\")\n",
    "\n",
    "data_ready = True\n",
    "\n",
    "# Kiem tra thu muc train\n",
    "if os.path.exists(train_img_dir):\n",
    "    train_identities = [d for d in os.listdir(train_img_dir) \n",
    "                        if os.path.isdir(os.path.join(train_img_dir, d))]\n",
    "    print(f\"[OK] Train folder: {len(train_identities)} identities\")\n",
    "    \n",
    "    # Dem so anh\n",
    "    total_train_images = 0\n",
    "    for identity in train_identities[:5]:  # Chi dem 5 identity dau\n",
    "        identity_path = os.path.join(train_img_dir, identity)\n",
    "        num_images = len([f for f in os.listdir(identity_path) \n",
    "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        total_train_images += num_images\n",
    "    print(f\"     Sample: {train_identities[:3]}...\")\n",
    "else:\n",
    "    print(f\"[ERROR] Train folder not found: {train_img_dir}\")\n",
    "    data_ready = False\n",
    "\n",
    "# Kiem tra thu muc val\n",
    "if os.path.exists(val_img_dir):\n",
    "    val_identities = [d for d in os.listdir(val_img_dir) \n",
    "                      if os.path.isdir(os.path.join(val_img_dir, d))]\n",
    "    print(f\"[OK] Val folder: {len(val_identities)} identities\")\n",
    "else:\n",
    "    print(f\"[ERROR] Val folder not found: {val_img_dir}\")\n",
    "    data_ready = False\n",
    "\n",
    "if data_ready:\n",
    "    print(\"\\n[OK] Du lieu san sang cho training!\")\n",
    "else:\n",
    "    print(\"\\n[ERROR] Thieu du lieu. Kiem tra lai dataset.\")\n",
    "    print(\"Cau truc thu muc can co:\")\n",
    "    print(\"  DATA_DIR/\")\n",
    "    print(\"    train/\")\n",
    "    print(\"      identity_1/\")\n",
    "    print(\"        img1.jpg, img2.jpg, ...\")\n",
    "    print(\"      identity_2/\")\n",
    "    print(\"        ...\")\n",
    "    print(\"    val/\")\n",
    "    print(\"      ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z",
     "iopub.execute_input": "2025-12-12T17:08:18.844163Z",
     "iopub.status.busy": "2025-12-12T17:08:18.843905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Chay training\n",
    "RESUME_FROM_LAST = True\n",
    "\n",
    "if not os.path.exists(TRAIN_SCRIPT):\n",
    "    print(f\"[ERROR] Training script not found: {TRAIN_SCRIPT}\")\n",
    "elif not os.path.exists(CONFIG_PATH):\n",
    "    print(f\"[ERROR] Config not found: {CONFIG_PATH}\")\n",
    "elif not data_ready:\n",
    "    print(\"[ERROR] Du lieu chua san sang!\")\n",
    "    print(\"Chay lai cell 'Kiem tra du lieu' o tren\")\n",
    "else:\n",
    "    print(\"=\"*60)\n",
    "    print(\"BAT DAU TRAINING ARCFACE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Config: {CONFIG_PATH}\")\n",
    "    print(f\"Data: {DATA_DIR}\")\n",
    "    print(f\"Train: {train_img_dir}\")\n",
    "    print(f\"Checkpoints: {CHECKPOINT_DIR}\")\n",
    "    \n",
    "    # Kiem tra checkpoint de resume\n",
    "    resume_arg = \"\"\n",
    "    last_checkpoint = os.path.join(CHECKPOINT_DIR, \"arcface_last.pth\")\n",
    "    if RESUME_FROM_LAST and os.path.exists(last_checkpoint):\n",
    "        resume_arg = f\"--resume {last_checkpoint}\"\n",
    "        print(f\"\\n[RESUME] Found checkpoint: {last_checkpoint}\")\n",
    "        ckpt = torch.load(last_checkpoint, map_location='cpu', weights_only=False)\n",
    "        print(f\"  Epoch: {ckpt['epoch']+1}\")\n",
    "        print(f\"  Best val acc: {ckpt['best_val_acc']:.2f}%\")\n",
    "    else:\n",
    "        print(\"\\n[NEW] Training tu dau\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    cmd = f\"python {TRAIN_SCRIPT} --config {CONFIG_PATH} --data_dir {DATA_DIR} --checkpoint_dir {CHECKPOINT_DIR} {resume_arg}\"\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Kiểm tra checkpoints sau training\n",
    "print(\"=== CHECKPOINTS ===\")\n",
    "if os.path.exists(CHECKPOINT_DIR):\n",
    "    !ls -lah {CHECKPOINT_DIR}\n",
    "else:\n",
    "    print(\"Chưa có checkpoint nào.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Kiểm tra đường dẫn hiện tại\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Liệt kê nội dung /kaggle/working\n",
    "print(\"\\nContent of /kaggle/working:\")\n",
    "for item in os.listdir('/kaggle/working'):\n",
    "    print(f\"  - {item}\")\n",
    "\n",
    "# Thêm đường dẫn\n",
    "repo_path = '/kaggle/working/FaceRecognition'\n",
    "if os.path.exists(repo_path):\n",
    "    sys.path.insert(0, repo_path)\n",
    "    print(f\"\\nAdded to sys.path: {repo_path}\")\n",
    "else:\n",
    "    print(f\"\\nPath not found: {repo_path}\")\n",
    "    print(\"Please check your repo path!\")\n",
    "\n",
    "print(\"\\nCurrent sys.path:\")\n",
    "for p in sys.path[:5]:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test import\n",
    "try:\n",
    "    from models.arcface.arcface_model import ArcFaceModel\n",
    "    print(\"Import thành công!\")\n",
    "    print(f\"ArcFaceModel: {ArcFaceModel}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    # Debug thêm\n",
    "    import os\n",
    "    models_path = '/kaggle/working/FaceRecognition/models'\n",
    "    print(f\"\\nKiểm tra thư mục models:\")\n",
    "    print(f\"  Tồn tại: {os.path.exists(models_path)}\")\n",
    "    if os.path.exists(models_path):\n",
    "        print(f\"  Nội dung: {os.listdir(models_path)}\")\n",
    "        \n",
    "    arcface_path = '/kaggle/working/FaceRecognition/models/arcface'\n",
    "    print(f\"\\nKiểm tra thư mục arcface:\")\n",
    "    print(f\"  Tồn tại: {os.path.exists(arcface_path)}\")\n",
    "    if os.path.exists(arcface_path):\n",
    "        print(f\"  Nội dung: {os.listdir(arcface_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test model sau training\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "\n",
    "checkpoint_path = os.path.join(CHECKPOINT_DIR, \"arcface_best.pth\")\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Testing model: {checkpoint_path}\")\n",
    "    \n",
    "    # Load module trực tiếp từ file\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        \"arcface_model\", \n",
    "        \"/kaggle/working/FaceRecognition/models/arcface/arcface_model.py\"\n",
    "    )\n",
    "    arcface_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(arcface_module)\n",
    "    ArcFaceModel = arcface_module.ArcFaceModel\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "    num_classes = checkpoint.get('num_classes', 100)\n",
    "    \n",
    "    model = ArcFaceModel(num_classes=num_classes, embedding_size=512)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"\\n[OK] Loaded model - Epoch {checkpoint.get('epoch', 'N/A')}\")\n",
    "    if 'val_acc' in checkpoint:\n",
    "        print(f\"Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    \n",
    "    dummy_input = torch.randn(1, 3, 112, 112)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.extract_features(dummy_input)\n",
    "    \n",
    "    print(f\"Embedding shape: {embedding.shape}\")\n",
    "    print(\"[OK] Model sẵn sàng!\")\n",
    "else:\n",
    "    print(f\"[WAIT] Chưa có checkpoint: {checkpoint_path}\")\n",
    "    print(\"Chạy cell training trước.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download checkpoints (QUAN TRỌNG - chạy trước khi session kết thúc)\n",
    "# Kaggle không lưu files sau khi session kết thúc!\n",
    "\n",
    "from IPython.display import FileLink, display\n",
    "import shutil\n",
    "\n",
    "print(\"=== DOWNLOAD CHECKPOINTS ===\")\n",
    "print(\"Quan trọng: Kaggle sẽ xóa files khi session kết thúc!\")\n",
    "print(\"Hãy download các checkpoints bên dưới:\\n\")\n",
    "\n",
    "# Copy checkpoints sang /kaggle/working để có thể download\n",
    "download_dir = \"/kaggle/working/download\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "checkpoints = [\"arcface_best.pth\", \"arcface_last.pth\"]\n",
    "for ckpt_name in checkpoints:\n",
    "    ckpt_path = os.path.join(CHECKPOINT_DIR, ckpt_name)\n",
    "    if os.path.exists(ckpt_path):\n",
    "        dest_path = os.path.join(download_dir, ckpt_name)\n",
    "        shutil.copy(ckpt_path, dest_path)\n",
    "        print(f\"[{ckpt_name}]\")\n",
    "        display(FileLink(dest_path))\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"[SKIP] {ckpt_name} - không tồn tại\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tạo file zip để download tất cả checkpoints\n",
    "import shutil\n",
    "\n",
    "zip_path = \"/kaggle/working/arcface_checkpoints\"\n",
    "if os.path.exists(CHECKPOINT_DIR) and os.listdir(CHECKPOINT_DIR):\n",
    "    shutil.make_archive(zip_path, 'zip', CHECKPOINT_DIR)\n",
    "    print(f\"Đã tạo: {zip_path}.zip\")\n",
    "    print(\"\\nClick link bên dưới để download:\")\n",
    "    display(FileLink(f\"{zip_path}.zip\"))\n",
    "else:\n",
    "    print(\"Chưa có checkpoints để zip.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nén logs\n",
    "log_dir = '/kaggle/working/FaceRecognition/logs/arcface'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.make_archive('/kaggle/working/arcface_logs', 'zip', log_dir)\n",
    "    display(FileLink('/kaggle/working/arcface_logs.zip'))\n",
    "    print(\"Click link trên để tải logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "execution_failed": "2025-12-12T17:09:17.599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ve bieu do training (Loss va Accuracy)\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def load_training_history():\n",
    "    \"\"\"Load history tu checkpoint hoac file JSON\"\"\"\n",
    "    history = None\n",
    "    \n",
    "    # Thu doc tu file JSON truoc\n",
    "    json_path = os.path.join(CHECKPOINT_DIR, 'training_history.json')\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            history = data.get('history', None)\n",
    "            print(f\"[OK] Loaded from: {json_path}\")\n",
    "    \n",
    "    # Neu khong co JSON, doc tu checkpoint\n",
    "    if history is None:\n",
    "        ckpt_path = os.path.join(CHECKPOINT_DIR, 'arcface_last.pth')\n",
    "        if os.path.exists(ckpt_path):\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "            history = ckpt.get('history', None)\n",
    "            print(f\"[OK] Loaded from checkpoint: {ckpt_path}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Ve bieu do Loss va Accuracy\"\"\"\n",
    "    if not history or len(history.get('epoch', [])) == 0:\n",
    "        print(\"[ERROR] Khong co du lieu training history\")\n",
    "        return\n",
    "    \n",
    "    epochs = history['epoch']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot Loss\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Training & Validation Loss', fontsize=14)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Danh dau epoch co val_loss thap nhat\n",
    "    best_loss_idx = history['val_loss'].index(min(history['val_loss']))\n",
    "    ax1.axvline(x=epochs[best_loss_idx], color='g', linestyle='--', alpha=0.7)\n",
    "    ax1.scatter([epochs[best_loss_idx]], [history['val_loss'][best_loss_idx]], \n",
    "                color='g', s=100, zorder=5, marker='*')\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.set_title('Training & Validation Accuracy', fontsize=14)\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Danh dau epoch co val_acc cao nhat\n",
    "    best_acc_idx = history['val_acc'].index(max(history['val_acc']))\n",
    "    ax2.axvline(x=epochs[best_acc_idx], color='g', linestyle='--', alpha=0.7)\n",
    "    ax2.scatter([epochs[best_acc_idx]], [history['val_acc'][best_acc_idx]], \n",
    "                color='g', s=100, zorder=5, marker='*')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Luu bieu do\n",
    "    plot_path = os.path.join(CHECKPOINT_DIR, 'training_plot.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n[OK] Saved plot: {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # In thong so\n",
    "    print(f\"\\n=== THONG SO TRAINING ===\")\n",
    "    print(f\"Tong so epochs: {len(epochs)}\")\n",
    "    print(f\"Best Val Loss: {min(history['val_loss']):.4f} (epoch {epochs[best_loss_idx]})\")\n",
    "    print(f\"Best Val Acc: {max(history['val_acc']):.2f}% (epoch {epochs[best_acc_idx]})\")\n",
    "    print(f\"Final Train Acc: {history['train_acc'][-1]:.2f}%\")\n",
    "    print(f\"Final Val Acc: {history['val_acc'][-1]:.2f}%\")\n",
    "    print(f\"Gap (Train - Val): {history['train_acc'][-1] - history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "# Load va ve bieu do\n",
    "print(\"=== VE BIEU DO TRAINING ===\")\n",
    "history = load_training_history()\n",
    "if history:\n",
    "    plot_training_history(history)\n",
    "else:\n",
    "    print(\"[WAIT] Chua co du lieu training. Chay cell training truoc.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8989978,
     "sourceId": 14112876,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
