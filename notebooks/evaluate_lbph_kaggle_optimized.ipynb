{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# LBPH Evaluation - Kaggle (Optimized)\n",
    "# \n",
    "# Phiên bản tối ưu với:\n",
    "# - Giới hạn max 3 ảnh/identity để giảm thời gian từ ~10h xuống vài phút\n",
    "# - Lưu intermediate results để phục hồi khi kernel restart\n",
    "# - File zip đầy đủ dữ liệu để trực quan hóa\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBPH Evaluation - Kaggle (Optimized)\n",
    "\n",
    "Evaluation notebook cho LBPH model sử dụng threshold-based classification.\n",
    "\n",
    "## Optimization:\n",
    "- **MAX_IMAGES_PER_IDENTITY = 3**: Giảm thời gian đánh giá từ ~10 tiếng xuống vài phút\n",
    "- **Intermediate logging**: Lưu kết quả sau mỗi bước để phục hồi khi session crash\n",
    "- **Extended zip file**: Bao gồm logs chi tiết để visualize offline\n",
    "\n",
    "## Approach:\n",
    "- Load LBPH model từ checkpoint (XML file)\n",
    "- Load validation và test datasets (giới hạn số ảnh)\n",
    "- Tìm threshold tối ưu trên validation set\n",
    "- Evaluate trên test set với threshold đã chọn\n",
    "- Metrics: Accuracy, Coverage, Threshold analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  !git config --global user.email \"phuctoan235@gmail.com\"\n",
    "  !git config --global user.name \"sin0235\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, json\n",
    "import shutil, glob\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "ROOT = \"/kaggle/working/FaceRecognition\"\n",
    "CHECKPOINT_DIR = \"/kaggle/working/checkpoints/lbph\"\n",
    "KAGGLE_DATASET_NAME = \"celeba-aligned-balanced\"\n",
    "DATA_DIR = f\"/kaggle/input/{KAGGLE_DATASET_NAME}\"\n",
    "CHECKPOINT_DATASET_NAME = \"lbph-checkpoints\"\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "LOG_DIR = f\"{OUTPUT_DIR}/logs/lbph\"\n",
    "\n",
    "# Giới hạn số identity và số ảnh để đánh giá nhanh\n",
    "# 200 identities * 3 ảnh = 600 samples → ~2-3 phút thay vì 1+ tiếng\n",
    "MAX_IDENTITIES = 200  # Số identity tối đa\n",
    "MAX_IMAGES_PER_IDENTITY = 3  # Số ảnh tối đa mỗi identity\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"[CONFIG] MAX_IDENTITIES = {MAX_IDENTITIES}\")\n",
    "print(f\"[CONFIG] MAX_IMAGES_PER_IDENTITY = {MAX_IMAGES_PER_IDENTITY}\")\n",
    "print(f\"[CONFIG] Expected samples: ~{MAX_IDENTITIES * MAX_IMAGES_PER_IDENTITY}\")\n",
    "print(f\"[CONFIG] LOG_DIR = {LOG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy checkpoint từ Kaggle input dataset (nếu có)\n",
    "checkpoint_input = f\"/kaggle/input/{CHECKPOINT_DATASET_NAME}\"\n",
    "checkpoint_found = False\n",
    "\n",
    "if os.path.exists(checkpoint_input):\n",
    "    for xml_file in glob.glob(os.path.join(checkpoint_input, \"**/*.xml\"), recursive=True):\n",
    "        dest = os.path.join(CHECKPOINT_DIR, os.path.basename(xml_file))\n",
    "        if not os.path.exists(dest) or os.path.getsize(dest) != os.path.getsize(xml_file):\n",
    "            print(f\"Copying {os.path.basename(xml_file)} from Kaggle input...\")\n",
    "            shutil.copy(xml_file, dest)\n",
    "            if os.path.getsize(dest) == os.path.getsize(xml_file):\n",
    "                print(f\"  [OK] Copied successfully\")\n",
    "                checkpoint_found = True\n",
    "            else:\n",
    "                print(f\"  [WARNING] Size mismatch after copy!\")\n",
    "        else:\n",
    "            checkpoint_found = True\n",
    "    if checkpoint_found:\n",
    "        print(f\"Checkpoints from Kaggle input: {os.listdir(CHECKPOINT_DIR)}\")\n",
    "else:\n",
    "    print(f\"[INFO] Không tìm thấy checkpoint trong Kaggle input: {checkpoint_input}\")\n",
    "    print(f\"      Sẽ thử copy từ repo sau khi clone...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cau hinh GitHub token\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "    print(\"[OK] Da lay GITHUB_TOKEN\")\n",
    "except Exception as e:\n",
    "    GITHUB_TOKEN = None\n",
    "    print(\"[INFO] Su dung public URL\")\n",
    "\n",
    "if GITHUB_TOKEN:\n",
    "    REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/sin0235/FaceRecognition.git\"\n",
    "else:\n",
    "    REPO_URL = \"https://github.com/sin0235/FaceRecognition.git\"\n",
    "\n",
    "# Clone repository\n",
    "if os.path.exists(ROOT):\n",
    "    print(\"Repository da ton tai, dang pull updates...\")\n",
    "    os.chdir(ROOT)\n",
    "    if GITHUB_TOKEN:\n",
    "        os.system(f\"git remote set-url origin {REPO_URL}\")\n",
    "    os.system(\"git pull --no-rebase origin fix/lbph-module\")\n",
    "else:\n",
    "    print(f\"Dang clone repository...\")\n",
    "    os.system(f\"git clone {REPO_URL} {ROOT}\")\n",
    "    os.chdir(ROOT)\n",
    "\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
    "\n",
    "# Thêm ROOT vào sys.path để import modules\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "    print(f\"\\n[OK] Added {ROOT} to sys.path\")\n",
    "\n",
    "# Copy checkpoint từ repo nếu chưa có từ Kaggle input\n",
    "model_path_check = os.path.join(CHECKPOINT_DIR, \"lbph_model.xml\")\n",
    "if not os.path.exists(model_path_check):\n",
    "    repo_checkpoint_path = os.path.join(ROOT, \"models\", \"checkpoints\", \"LBHP\", \"lbph_model.xml\")\n",
    "    if os.path.exists(repo_checkpoint_path):\n",
    "        print(f\"\\nCopying checkpoint from repo: {repo_checkpoint_path}\")\n",
    "        shutil.copy(repo_checkpoint_path, model_path_check)\n",
    "        if os.path.exists(model_path_check):\n",
    "            file_size = os.path.getsize(model_path_check)\n",
    "            print(f\"  [OK] Copied successfully ({file_size / 1024 / 1024:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"  [ERROR] Failed to copy checkpoint\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Không tìm thấy checkpoint trong repo: {repo_checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"\\n[OK] Checkpoint đã có sẵn: {model_path_check}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hủy merge đang dở\n",
    "!git merge --abort\n",
    "\n",
    "# Fetch nhánh từ remote\n",
    "!git fetch origin fix/lbph-module\n",
    "\n",
    "# Reset local về nhánh remote (xóa toàn bộ thay đổi local)\n",
    "!git reset --hard origin/fix/lbph-module\n",
    "!git pull --no-rebase origin fix/lbph-module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHỈ install opencv-contrib-python-headless\n",
    "# KHÔNG upgrade numpy/scipy vì sẽ phá vỡ các packages pre-installed của Kaggle\n",
    "!pip install -q opencv-contrib-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import các thư viện có sẵn trên Kaggle (KHÔNG reinstall)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(\"[OK] All imports successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(CHECKPOINT_DIR, \"lbph_model.xml\")\n",
    "\n",
    "# Validate checkpoint file trước khi load\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Model không tồn tại: {model_path}\\n\"\n",
    "        f\"Vui lòng kiểm tra:\"\n",
    "        f\"  1. Dataset checkpoint đã được add vào Kaggle input chưa?\"\n",
    "        f\"  2. Tên dataset có đúng '{CHECKPOINT_DATASET_NAME}' không?\"\n",
    "        f\"  3. File lbph_model.xml có trong dataset không?\"\n",
    "    )\n",
    "\n",
    "file_size = os.path.getsize(model_path)\n",
    "print(f\"Model file: {model_path}\")\n",
    "print(f\"File size: {file_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "if file_size < 1024:\n",
    "    raise ValueError(f\"Model file quá nhỏ ({file_size} bytes), có thể bị hỏng\")\n",
    "\n",
    "# Load LBPH model\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.read(model_path)\n",
    "\n",
    "print(f\"\\n[OK] LBPH model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data (với giới hạn số ảnh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lbphmodel.dataset_lbph import load_data_no_haar\n",
    "\n",
    "# Tìm data dirs\n",
    "train_dir = os.path.join(DATA_DIR, \"CelebA_Aligned_Balanced\", \"train\")\n",
    "val_dir = os.path.join(DATA_DIR, \"CelebA_Aligned_Balanced\", \"val\")\n",
    "test_dir = os.path.join(DATA_DIR, \"CelebA_Aligned_Balanced\", \"test\")\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "    val_dir = os.path.join(DATA_DIR, \"val\")\n",
    "    test_dir = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "print(f\"Train dir: {train_dir}\")\n",
    "print(f\"Val dir: {val_dir}\")\n",
    "print(f\"Test dir: {test_dir}\")\n",
    "\n",
    "# Load validation và test data với giới hạn\n",
    "# Giúp giảm thời gian đánh giá từ ~1 tiếng xuống ~2-3 phút\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Loading VALIDATION data...\")\n",
    "val_faces, val_labels = load_data_no_haar(\n",
    "    val_dir, \n",
    "    max_images_per_identity=MAX_IMAGES_PER_IDENTITY,\n",
    "    max_identities=MAX_IDENTITIES\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Loading TEST data...\")\n",
    "test_faces, test_labels = load_data_no_haar(\n",
    "    test_dir, \n",
    "    max_images_per_identity=MAX_IMAGES_PER_IDENTITY,\n",
    "    max_identities=MAX_IDENTITIES\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"DATA SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Val samples: {len(val_faces)}\")\n",
    "print(f\"Test samples: {len(test_faces)}\")\n",
    "print(f\"Val identities: {len(set(val_labels))}\")\n",
    "print(f\"Test identities: {len(set(test_labels))}\")\n",
    "\n",
    "# Lưu thông tin data load để phục hồi\n",
    "data_info = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'max_identities': MAX_IDENTITIES,\n",
    "    'max_images_per_identity': MAX_IMAGES_PER_IDENTITY,\n",
    "    'val_samples': len(val_faces),\n",
    "    'test_samples': len(test_faces),\n",
    "    'val_identities': len(set(val_labels)),\n",
    "    'test_identities': len(set(test_labels))\n",
    "}\n",
    "with open(f'{LOG_DIR}/data_info.json', 'w') as f:\n",
    "    json.dump(data_info, f, indent=2)\n",
    "print(f\"\\n[OK] Data info saved to {LOG_DIR}/data_info.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Find Optimal Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lbphmodel.threshold_lbph import find_optimal_threshold\n",
    "\n",
    "# Tìm threshold tối ưu trên validation set\n",
    "print(\"Finding optimal threshold on validation set...\")\n",
    "start_time = time.time()\n",
    "best_threshold, best_score, threshold_results = find_optimal_threshold(\n",
    "    model, val_faces, val_labels, min_coverage=0.3\n",
    ")\n",
    "threshold_search_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"OPTIMAL THRESHOLD\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Search time: {threshold_search_time:.2f}s ({threshold_search_time/60:.2f} min)\")\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best score (acc * coverage): {best_score:.4f}\")\n",
    "print(f\"\\nTop 5 thresholds:\")\n",
    "for thr, acc, cov, score in sorted(threshold_results, key=lambda x: x[3], reverse=True)[:5]:\n",
    "    print(f\"  Threshold={thr:3d}: Accuracy={acc:.3f}, Coverage={cov:.3f}, Score={score:.4f}\")\n",
    "\n",
    "# Lưu kết quả threshold ngay lập tức để tránh mất dữ liệu\n",
    "threshold_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'search_time_seconds': threshold_search_time,\n",
    "    'best_threshold': int(best_threshold),\n",
    "    'best_score': float(best_score),\n",
    "    'all_results': [{'threshold': int(t), 'accuracy': float(a), 'coverage': float(c), 'score': float(s)} for t, a, c, s in threshold_results]\n",
    "}\n",
    "with open(f'{LOG_DIR}/threshold_search.json', 'w') as f:\n",
    "    json.dump(threshold_data, f, indent=2)\n",
    "print(f\"\\n[OK] Threshold results saved to {LOG_DIR}/threshold_search.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Evaluate on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lbphmodel.evaluate_lbph import evaluate_lbph\n",
    "\n",
    "# Evaluate trên test set với threshold đã chọn\n",
    "start_time = time.time()\n",
    "test_acc, test_cov, test_used, test_confidences = evaluate_lbph(\n",
    "    model, test_faces, test_labels, best_threshold\n",
    ")\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TEST SET EVALUATION\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Evaluation time: {eval_time:.2f}s ({eval_time/60:.2f} min)\")\n",
    "print(f\"Threshold: {best_threshold}\")\n",
    "print(f\"Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Coverage: {test_cov:.4f} ({test_cov*100:.2f}%)\")\n",
    "print(f\"Used samples: {test_used} / {len(test_labels)}\")\n",
    "print(f\"Rejected samples: {len(test_labels) - test_used}\")\n",
    "\n",
    "# Lưu kết quả test ngay lập tức\n",
    "test_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'eval_time_seconds': eval_time,\n",
    "    'threshold': int(best_threshold),\n",
    "    'accuracy': float(test_acc),\n",
    "    'coverage': float(test_cov),\n",
    "    'used_samples': int(test_used),\n",
    "    'total_samples': len(test_labels),\n",
    "    'rejected_samples': len(test_labels) - test_used,\n",
    "    'confidence_stats': {\n",
    "        'min': float(test_confidences.min()),\n",
    "        'max': float(test_confidences.max()),\n",
    "        'mean': float(test_confidences.mean()),\n",
    "        'std': float(test_confidences.std())\n",
    "    }\n",
    "}\n",
    "with open(f'{LOG_DIR}/test_evaluation.json', 'w') as f:\n",
    "    json.dump(test_data, f, indent=2)\n",
    "print(f\"\\n[OK] Test results saved to {LOG_DIR}/test_evaluation.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Analysis Plot\n",
    "thresholds = [r[0] for r in threshold_results]\n",
    "accuracies = [r[1] for r in threshold_results]\n",
    "coverages = [r[2] for r in threshold_results]\n",
    "scores = [r[3] for r in threshold_results]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Accuracy vs Threshold\n",
    "axes[0].plot(thresholds, accuracies, 'b-o', label='Accuracy')\n",
    "axes[0].axvline(best_threshold, color='r', linestyle='--', label=f'Best threshold={best_threshold}')\n",
    "axes[0].set_xlabel('Threshold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy vs Threshold')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "# Coverage vs Threshold\n",
    "axes[1].plot(thresholds, coverages, 'g-o', label='Coverage')\n",
    "axes[1].axvline(best_threshold, color='r', linestyle='--', label=f'Best threshold={best_threshold}')\n",
    "axes[1].set_xlabel('Threshold')\n",
    "axes[1].set_ylabel('Coverage')\n",
    "axes[1].set_title('Coverage vs Threshold')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "# Score vs Threshold\n",
    "axes[2].plot(thresholds, scores, 'm-o', label='Score (acc * cov)')\n",
    "axes[2].axvline(best_threshold, color='r', linestyle='--', label=f'Best threshold={best_threshold}')\n",
    "axes[2].set_xlabel('Threshold')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].set_title('Score (Accuracy * Coverage) vs Threshold')\n",
    "axes[2].grid(True)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lbph_threshold_analysis.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(test_confidences, bins=50, edgecolor='black')\n",
    "plt.axvline(best_threshold, color='r', linestyle='--', linewidth=2, label=f'Threshold={best_threshold}')\n",
    "plt.xlabel('Confidence (lower is better)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Test Set Confidence Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Predictions để tính confusion matrix\n",
    "test_predictions = []\n",
    "test_true_labels_filtered = []\n",
    "for img, true_label in zip(test_faces, test_labels):\n",
    "    pred, conf = model.predict(img)\n",
    "    if conf < best_threshold:\n",
    "        test_predictions.append(pred)\n",
    "        test_true_labels_filtered.append(true_label)\n",
    "\n",
    "if len(test_predictions) > 0:\n",
    "    cm = confusion_matrix(test_true_labels_filtered, test_predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix (Threshold={best_threshold})')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No predictions above threshold', ha='center', va='center')\n",
    "    plt.title('Confusion Matrix (No data)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/lbph_confusion_matrix.png', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Export Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV và JSON\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    os.system(\"pip install -q pandas\")\n",
    "    import pandas as pd\n",
    "\n",
    "# 1. Export predictions CSV\n",
    "predictions_data = []\n",
    "for img, true_label in zip(test_faces, test_labels):\n",
    "    pred, conf = model.predict(img)\n",
    "    predictions_data.append({\n",
    "        'true_label': int(true_label),\n",
    "        'pred_label': int(pred),\n",
    "        'confidence': float(conf),\n",
    "        'accepted': conf < best_threshold,\n",
    "        'is_correct': pred == true_label if conf < best_threshold else False\n",
    "    })\n",
    "\n",
    "df_predictions = pd.DataFrame(predictions_data)\n",
    "df_predictions.to_csv(f'{OUTPUT_DIR}/lbph_predictions.csv', index=False)\n",
    "print(f\"[OK] Exported predictions CSV: {len(df_predictions)} samples\")\n",
    "\n",
    "# 2. Export threshold results CSV\n",
    "df_thresholds = pd.DataFrame(threshold_results, columns=['threshold', 'accuracy', 'coverage', 'score'])\n",
    "df_thresholds.to_csv(f'{OUTPUT_DIR}/lbph_threshold_results.csv', index=False)\n",
    "print(f\"[OK] Exported threshold results CSV\")\n",
    "\n",
    "# 3. Export evaluation report JSON\n",
    "report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'LBPH',\n",
    "    'method': 'threshold-based classification',\n",
    "    'optimal_threshold': int(best_threshold),\n",
    "    'max_images_per_identity': MAX_IMAGES_PER_IDENTITY,\n",
    "    'timing': {\n",
    "        'threshold_search_seconds': threshold_search_time,\n",
    "        'test_eval_seconds': eval_time\n",
    "    },\n",
    "    'metrics': {\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'test_coverage': float(test_cov),\n",
    "        'test_used_samples': int(test_used),\n",
    "        'test_total_samples': int(len(test_labels))\n",
    "    },\n",
    "    'threshold_results': [\n",
    "        {'threshold': int(t), 'accuracy': float(a), 'coverage': float(c), 'score': float(s)}\n",
    "        for t, a, c, s in threshold_results\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/lbph_evaluation_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"[OK] Exported evaluation report JSON\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"LBPH FINAL REPORT\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Optimal Threshold: {best_threshold}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Test Coverage: {test_cov:.4f} ({test_cov*100:.2f}%)\")\n",
    "print(f\"Used Samples: {test_used} / {len(test_labels)}\")\n",
    "print(f\"\\nReport saved to: lbph_evaluation_report.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip tất cả kết quả để download\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "log_dir = Path(LOG_DIR)\n",
    "zip_path = output_dir / 'lbph_evaluation_results.zip'\n",
    "\n",
    "# Danh sách các file cần zip - bao gồm cả intermediate logs\n",
    "files_to_zip = [\n",
    "    # Reports và metrics chính\n",
    "    'lbph_evaluation_report.json',\n",
    "    # CSV files\n",
    "    'lbph_predictions.csv',\n",
    "    'lbph_threshold_results.csv',\n",
    "    # Visualization plots\n",
    "    'lbph_threshold_analysis.png',\n",
    "    'lbph_confusion_matrix.png'\n",
    "]\n",
    "\n",
    "# Các file log intermediate\n",
    "log_files = [\n",
    "    'data_info.json',\n",
    "    'threshold_search.json',\n",
    "    'test_evaluation.json'\n",
    "]\n",
    "\n",
    "# Tạo zip file\n",
    "added_files = []\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Thêm files từ output_dir\n",
    "    for file_name in files_to_zip:\n",
    "        file_path = output_dir / file_name\n",
    "        if file_path.exists():\n",
    "            file_size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            zipf.write(file_path, file_name)\n",
    "            print(f\"[OK] Added {file_name} ({file_size_mb:.2f} MB)\")\n",
    "            added_files.append(file_name)\n",
    "        else:\n",
    "            print(f\"[WARNING] {file_name} not found, skipping\")\n",
    "    \n",
    "    # Thêm files từ log_dir với prefix logs/\n",
    "    for file_name in log_files:\n",
    "        file_path = log_dir / file_name\n",
    "        if file_path.exists():\n",
    "            file_size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            zipf.write(file_path, f'logs/{file_name}')\n",
    "            print(f\"[OK] Added logs/{file_name} ({file_size_mb:.4f} MB)\")\n",
    "            added_files.append(f'logs/{file_name}')\n",
    "        else:\n",
    "            print(f\"[WARNING] logs/{file_name} not found, skipping\")\n",
    "    \n",
    "    # Thêm confidence distribution data (để phục hồi nếu cần)\n",
    "    conf_data = {'confidences': test_confidences.tolist()}\n",
    "    conf_path = output_dir / 'confidence_distribution.json'\n",
    "    with open(conf_path, 'w') as f:\n",
    "        json.dump(conf_data, f)\n",
    "    zipf.write(conf_path, 'confidence_distribution.json')\n",
    "    added_files.append('confidence_distribution.json')\n",
    "    print(f\"[OK] Added confidence_distribution.json\")\n",
    "\n",
    "# Hiển thị thông tin\n",
    "if zip_path.exists():\n",
    "    zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ZIP FILE CREATED: {zip_path.name}\")\n",
    "    print(f\"Size: {zip_size_mb:.2f} MB\")\n",
    "    print(f\"Files included: {len(added_files)}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(\"\\nFiles trong zip:\")\n",
    "    for f in added_files:\n",
    "        print(f\"  - {f}\")\n",
    "    print(\"\\nLưu ý: Zip file bao gồm intermediate logs để phục hồi kết quả nếu session bị ngắt.\")\n",
    "    print(\"\\nĐể download:\")\n",
    "    print(\"1. Click vào file 'lbph_evaluation_results.zip' trong panel bên phải\")\n",
    "    print(\"2. Hoặc chạy: !cp lbph_evaluation_results.zip /kaggle/working/\")\n",
    "else:\n",
    "    print(\"[ERROR] Failed to create zip file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
